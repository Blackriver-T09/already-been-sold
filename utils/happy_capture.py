import cv2
import os
import time
from datetime import datetime
import numpy as np

# åœ¨æ–‡ä»¶å¼€å¤´æ·»åŠ å¯¼å…¥
from utils.image_composer import ImageComposer

class HappyCaptureManager:
    """å¿«ä¹ç¬é—´æ•æ‰ç®¡ç†å™¨"""
    
    def __init__(self, capture_interval=10, save_directory="pictures"):
        """
        åˆå§‹åŒ–æ•æ‰ç®¡ç†å™¨
        
        å‚æ•°:
            capture_interval: æ•æ‰é—´éš”ï¼ˆç§’ï¼‰
            save_directory: ä¿å­˜ç›®å½•
        """
        self.capture_interval = capture_interval
        self.save_directory = save_directory
        self.last_capture_time = 0
        self.capture_count = 0
        
        # ğŸ†• å›è°ƒå‡½æ•°
        self.photo_callback = None
        
        # ğŸ†• å¯è§†åŒ–æŒ‡ç¤ºå™¨
        self.last_capture_visual_indicator = False
        self.last_captured_person = None
        self.visual_indicator_start_time = 0
        self.visual_indicator_duration = 3.0  # æ˜¾ç¤º3ç§’
        
        # ğŸ†• åˆå§‹åŒ–å›¾ç‰‡åˆæˆå™¨
        self.image_composer = ImageComposer(sources_dir="sources")
        
        # ç¡®ä¿ä¿å­˜ç›®å½•å­˜åœ¨
        self.ensure_directory_exists()
    
    def ensure_directory_exists(self):
        """ç¡®ä¿ä¿å­˜ç›®å½•å­˜åœ¨"""
        if not os.path.exists(self.save_directory):
            os.makedirs(self.save_directory)
            print(f"ğŸ“ åˆ›å»ºç›®å½•: {self.save_directory}")
    
    def set_photo_callback(self, callback_func):
        """
        è®¾ç½®æ‹ç…§å›è°ƒå‡½æ•°
        
        å‚æ•°:
            callback_func: å›è°ƒå‡½æ•°ï¼Œç­¾åä¸º callback_func(photo_info)
        """
        self.photo_callback = callback_func
        print("âœ… è®¾ç½®æ‹ç…§å›è°ƒå‡½æ•°")
    
    def should_capture_now(self):
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥æ‰§è¡Œæ•æ‰
        
        è¿”å›:
            bool: æ˜¯å¦åº”è¯¥æ•æ‰
        """
        current_time = time.time()
        if current_time - self.last_capture_time >= self.capture_interval:
            return True
        return False
    
    def find_target_person(self, detected_faces_data):
        """
        æ‰¾åˆ°ç›®æ ‡äººç‰©ï¼ˆä¼˜å…ˆçº§ï¼šHappy > Surprise > Sad > Angryï¼‰
        
        å‚æ•°:
            detected_faces_data: æ£€æµ‹åˆ°çš„äººè„¸æ•°æ®åˆ—è¡¨
            æ ¼å¼: [{'face_id': int, 'emotion_data': dict, 'face_info': dict}, ...]
        
        è¿”å›:
            dict: ç›®æ ‡äººç‰©çš„ä¿¡æ¯ï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ™è¿”å›None
            åŒ…å«é¢å¤–å­—æ®µ: 'capture_reason' - æ•æ‰åŸå› 
        """
        if not detected_faces_data:
            return None
        
        # ğŸ¯ ç¬¬ä¸€ä¼˜å…ˆçº§ï¼šå¯»æ‰¾æœ€å¿«ä¹çš„äºº
        happiest_person = None
        max_happy_score = 0
        
        for person_data in detected_faces_data:
            emotion_data = person_data.get('emotion_data')
            if not emotion_data:
                continue
            
            all_emotions = emotion_data.get('all_emotions', {})
            happy_score = all_emotions.get('happy', 0)
            
            # å¯»æ‰¾happyæƒ…æ„Ÿæ˜æ˜¾çš„äººï¼ˆè‡³å°‘25%çš„happyï¼‰
            if happy_score > max_happy_score and happy_score > 25:
                max_happy_score = happy_score
                happiest_person = person_data.copy()
                happiest_person['capture_reason'] = 'happy'
                happiest_person['emotion_score'] = happy_score
        
        # å¦‚æœæ‰¾åˆ°äº†è¶³å¤Ÿå¿«ä¹çš„äººï¼Œç›´æ¥è¿”å›
        if happiest_person:
            return happiest_person
        
        # ğŸ¯ ç¬¬äºŒä¼˜å…ˆçº§ï¼šå¯»æ‰¾æœ€æƒŠè®¶çš„äºº
        most_surprised_person = None
        max_surprise_score = 0
        
        for person_data in detected_faces_data:
            emotion_data = person_data.get('emotion_data')
            if not emotion_data:
                continue
            
            all_emotions = emotion_data.get('all_emotions', {})
            surprise_score = all_emotions.get('surprise', 0)
            
            # å¯»æ‰¾surpriseæƒ…æ„Ÿæ˜æ˜¾çš„äººï¼ˆè‡³å°‘25%çš„surpriseï¼‰
            if surprise_score > max_surprise_score and surprise_score > 25:
                max_surprise_score = surprise_score
                most_surprised_person = person_data.copy()
                most_surprised_person['capture_reason'] = 'surprise'
                most_surprised_person['emotion_score'] = surprise_score
        
        # å¦‚æœæ‰¾åˆ°äº†è¶³å¤ŸæƒŠè®¶çš„äººï¼Œè¿”å›
        if most_surprised_person:
            return most_surprised_person
        
        # ğŸ¯ ç¬¬ä¸‰ä¼˜å…ˆçº§ï¼šå¯»æ‰¾æœ€æ‚²ä¼¤çš„äºº
        saddest_person = None
        max_sad_score = 0
        
        for person_data in detected_faces_data:
            emotion_data = person_data.get('emotion_data')
            if not emotion_data:
                continue
            
            all_emotions = emotion_data.get('all_emotions', {})
            sad_score = all_emotions.get('sad', 0)
            
            # å¯»æ‰¾sadæƒ…æ„Ÿæ˜æ˜¾çš„äººï¼ˆè‡³å°‘30%çš„sadï¼‰
            if sad_score > max_sad_score and sad_score > 30:
                max_sad_score = sad_score
                saddest_person = person_data.copy()
                saddest_person['capture_reason'] = 'sad'
                saddest_person['emotion_score'] = sad_score
        
        # å¦‚æœæ‰¾åˆ°äº†è¶³å¤Ÿæ‚²ä¼¤çš„äººï¼Œè¿”å›
        if saddest_person:
            return saddest_person
        
        # ğŸ¯ ç¬¬å››ä¼˜å…ˆçº§ï¼šå¯»æ‰¾æœ€æ„¤æ€’çš„äºº
        angriest_person = None
        max_angry_score = 0
        
        for person_data in detected_faces_data:
            emotion_data = person_data.get('emotion_data')
            if not emotion_data:
                continue
            
            all_emotions = emotion_data.get('all_emotions', {})
            angry_score = all_emotions.get('angry', 0)
            
            # å¯»æ‰¾angryæƒ…æ„Ÿæ˜æ˜¾çš„äººï¼ˆè‡³å°‘25%çš„angryï¼‰
            if angry_score > max_angry_score and angry_score > 25:
                max_angry_score = angry_score
                angriest_person = person_data.copy()
                angriest_person['capture_reason'] = 'angry'
                angriest_person['emotion_score'] = angry_score
        
        # è¿”å›æœ€æ„¤æ€’çš„äººï¼Œå¦‚æœéƒ½æ²¡æœ‰åˆ™è¿”å›None
        return angriest_person

    def calculate_capture_region(self, face_bbox, image_shape, scale_factor=3.0):
        """
        è®¡ç®—æˆªå›¾åŒºåŸŸï¼ˆ1:1æ­£æ–¹å½¢ï¼Œè¦†ç›–åˆ°èƒ¸å£ï¼‰
        é‡æ–°è®¾è®¡ç®—æ³•ï¼Œç¡®ä¿ç»å¯¹çš„æ­£æ–¹å½¢
        
        å‚æ•°:
            face_bbox: äººè„¸è¾¹ç•Œæ¡† (x, y, w, h)
            image_shape: å›¾åƒå°ºå¯¸ (height, width, channels)
            scale_factor: ç¼©æ”¾å› å­ï¼Œæ§åˆ¶æˆªå›¾å¤§å°
        
        è¿”å›:
            tuple: (x1, y1, x2, y2) æˆªå›¾åŒºåŸŸåæ ‡
        """
        x, y, w, h = face_bbox
        image_height, image_width = image_shape[:2]
        
        # è®¡ç®—äººè„¸ä¸­å¿ƒç‚¹
        face_center_x = x + w // 2
        face_center_y = y + h // 2
        
        # è®¡ç®—ç†æƒ³çš„æ­£æ–¹å½¢è¾¹é•¿
        ideal_size = int(h * scale_factor)
        
        # ğŸ†• å…³é”®æ”¹è¿›ï¼šç›´æ¥è®¡ç®—åœ¨å›¾åƒè¾¹ç•Œå†…èƒ½å®¹çº³çš„æœ€å¤§æ­£æ–¹å½¢
        max_possible_size = self._calculate_max_square_size(
            face_center_x, face_center_y, image_width, image_height
        )
        
        # é€‰æ‹©åˆé€‚çš„å°ºå¯¸
        actual_size = min(ideal_size, max_possible_size)
        
        # ğŸ†• å¦‚æœå°ºå¯¸å¤ªå°ï¼Œè°ƒæ•´ä¸­å¿ƒç‚¹æ¥è·å¾—æ›´å¤§çš„æ­£æ–¹å½¢
        if actual_size < ideal_size * 0.8:  # å¦‚æœå°äºç†æƒ³å°ºå¯¸çš„80%
            # å¯»æ‰¾æœ€ä½³ä¸­å¿ƒç‚¹ä½ç½®
            optimal_center, optimal_size = self._find_optimal_center_and_size(
                face_center_x, face_center_y, ideal_size, image_width, image_height
            )
            face_center_x, face_center_y = optimal_center
            actual_size = optimal_size
        
        # ğŸ†• è®¡ç®—å®Œç¾æ­£æ–¹å½¢ï¼ˆè¿™é‡Œç»å¯¹ä¸ä¼šè¶…å‡ºè¾¹ç•Œï¼‰
        half_size = actual_size // 2
        
        x1 = face_center_x - half_size
        y1 = face_center_y - half_size
        x2 = face_center_x + half_size
        y2 = face_center_y + half_size
        
        # éªŒè¯ç»“æœ
        final_width = x2 - x1
        final_height = y2 - y1
        
        # æˆªå›¾åŒºåŸŸè®¡ç®—è°ƒè¯•ä¿¡æ¯ï¼ˆå·²ç¦ç”¨ä»¥å‡å°‘æ§åˆ¶å°è¾“å‡ºï¼‰
        # print(f"ğŸ” æˆªå›¾åŒºåŸŸè®¡ç®—:")
        # print(f"   äººè„¸ä½ç½®: ({x}, {y}, {w}, {h})")
        # print(f"   äººè„¸ä¸­å¿ƒ: ({face_center_x}, {face_center_y})")
        # print(f"   å›¾åƒå°ºå¯¸: {image_width}x{image_height}")
        # print(f"   ç†æƒ³å°ºå¯¸: {ideal_size}x{ideal_size}")
        # print(f"   å®é™…å°ºå¯¸: {final_width}x{final_height}")
        # print(f"   æˆªå›¾åŒºåŸŸ: ({x1}, {y1}) â†’ ({x2}, {y2})")
        # print(f"   âœ… å®Œç¾æ­£æ–¹å½¢: {final_width == final_height}")
        
        return (x1, y1, x2, y2)

    def _calculate_max_square_size(self, center_x, center_y, img_width, img_height):
        """
        è®¡ç®—åœ¨ç»™å®šä¸­å¿ƒç‚¹ä¸‹èƒ½å®¹çº³çš„æœ€å¤§æ­£æ–¹å½¢å°ºå¯¸
        
        å‚æ•°:
            center_x, center_y: ä¸­å¿ƒç‚¹åæ ‡
            img_width, img_height: å›¾åƒå°ºå¯¸
        
        è¿”å›:
            int: æœ€å¤§æ­£æ–¹å½¢è¾¹é•¿
        """
        # è®¡ç®—å„æ–¹å‘åˆ°è¾¹ç•Œçš„è·ç¦»
        dist_to_left = center_x
        dist_to_right = img_width - center_x
        dist_to_top = center_y
        dist_to_bottom = img_height - center_y
        
        # æœ€å¤§æ­£æ–¹å½¢çš„åŠè¾¹é•¿æ˜¯åˆ°æœ€è¿‘è¾¹ç•Œè·ç¦»çš„ä¸¤å€
        max_half_size = min(dist_to_left, dist_to_right, dist_to_top, dist_to_bottom)
        
        return max_half_size * 2

    def _find_optimal_center_and_size(self, preferred_center_x, preferred_center_y, 
                                     desired_size, img_width, img_height):
        """
        å¯»æ‰¾æœ€ä½³çš„ä¸­å¿ƒç‚¹å’Œå°ºå¯¸ç»„åˆ
        
        å‚æ•°:
            preferred_center_x, preferred_center_y: é¦–é€‰ä¸­å¿ƒç‚¹
            desired_size: æœŸæœ›çš„æ­£æ–¹å½¢å°ºå¯¸
            img_width, img_height: å›¾åƒå°ºå¯¸
        
        è¿”å›:
            tuple: ((best_center_x, best_center_y), best_size)
        """
        # é¦–å…ˆå°è¯•é€‚åº”æœŸæœ›å°ºå¯¸æ‰€éœ€çš„è¾¹ç•Œçº¦æŸ
        half_desired = desired_size // 2
        
        # è®¡ç®—èƒ½å®¹çº³æœŸæœ›å°ºå¯¸çš„ä¸­å¿ƒç‚¹èŒƒå›´
        min_center_x = half_desired
        max_center_x = img_width - half_desired
        min_center_y = half_desired  
        max_center_y = img_height - half_desired
        
        # æ£€æŸ¥æ˜¯å¦èƒ½åœ¨å›¾åƒå†…å®¹çº³æœŸæœ›å°ºå¯¸
        if (min_center_x <= max_center_x and min_center_y <= max_center_y):
            # å¯ä»¥å®¹çº³æœŸæœ›å°ºå¯¸ï¼Œè°ƒæ•´ä¸­å¿ƒç‚¹åˆ°æœ€è¿‘çš„æœ‰æ•ˆä½ç½®
            best_center_x = max(min_center_x, min(max_center_x, preferred_center_x))
            best_center_y = max(min_center_y, min(max_center_y, preferred_center_y))
            return (best_center_x, best_center_y), desired_size
        
        # æ— æ³•å®¹çº³æœŸæœ›å°ºå¯¸ï¼Œä½¿ç”¨å›¾åƒå…è®¸çš„æœ€å¤§å°ºå¯¸
        max_possible_size = min(img_width, img_height)
        half_max = max_possible_size // 2
        
        # ä½¿ç”¨å›¾åƒä¸­å¿ƒä½œä¸ºæœ€ä½³ä½ç½®
        best_center_x = img_width // 2
        best_center_y = img_height // 2
        
        return (best_center_x, best_center_y), max_possible_size
    
    def generate_filename(self):
        """
        ç”Ÿæˆæ–‡ä»¶å
        
        è¿”å›:
            str: æ–‡ä»¶å
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.capture_count += 1
        filename = f"happy_moment_{timestamp}_{self.capture_count:04d}.jpg"
        return filename

    def generate_emotion_filename(self, emotion_type, emotion_score):
        """
        æ ¹æ®æƒ…æ„Ÿç±»å‹ç”Ÿæˆæ–‡ä»¶å
        
        å‚æ•°:
            emotion_type: æƒ…æ„Ÿç±»å‹ ('happy', 'sad', 'angry')
            emotion_score: æƒ…æ„Ÿåˆ†æ•°
        
        è¿”å›:
            str: æ–‡ä»¶å
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.capture_count += 1
        filename = f"{emotion_type}_moment_{timestamp}_{self.capture_count:04d}_({emotion_score:.0f}%).jpg"
        return filename
    
    def capture_happy_moment(self, original_image, detected_faces_data):
        """
        æ•æ‰æƒ…æ„Ÿç¬é—´ï¼ˆä½¿ç”¨åŸå§‹å›¾åƒï¼‰+ è‡ªåŠ¨åˆæˆ
        ä¼˜å…ˆçº§ï¼šHappy > Surprise > Sad > Angry
        
        å‚æ•°:
            original_image: åŸå§‹å›¾åƒï¼ˆæ— ä»»ä½•ç»˜åˆ¶ï¼‰
            detected_faces_data: æ£€æµ‹åˆ°çš„äººè„¸æ•°æ®åˆ—è¡¨
        
        è¿”å›:
            bool: æ˜¯å¦æˆåŠŸæ•æ‰
        """
        # é‡ç½®å¯è§†åŒ–æŒ‡ç¤ºå™¨ï¼ˆå¦‚æœè¶…æ—¶ï¼‰
        if (self.last_capture_visual_indicator and 
            time.time() - self.visual_indicator_start_time > self.visual_indicator_duration):
            self.last_capture_visual_indicator = False
            self.last_captured_person = None
        
        if not self.should_capture_now():
            return False
        
        # ğŸ†• ç«‹å³æ›´æ–°æ—¶é—´æˆ³ï¼Œé˜²æ­¢é‡å¤è§¦å‘
        self.last_capture_time = time.time()
        
        # ğŸ†• ä½¿ç”¨æ–°çš„ç›®æ ‡æŸ¥æ‰¾é€»è¾‘
        target_person = self.find_target_person(detected_faces_data)
        if not target_person:
            print("âš ï¸ æœªæ‰¾åˆ°åˆé€‚çš„æƒ…æ„Ÿç›®æ ‡ï¼Œè·³è¿‡æ•æ‰")
            return False
        
        face_info = target_person['face_info']
        emotion_data = target_person['emotion_data']
        face_id = target_person['face_id']
        capture_reason = target_person['capture_reason']
        emotion_score = target_person['emotion_score']
        
        # è®¡ç®—æˆªå›¾åŒºåŸŸï¼ˆå·²ç»æ˜¯å®Œç¾æ­£æ–¹å½¢ï¼‰
        capture_region = self.calculate_capture_region(
            face_info['bbox'], original_image.shape
        )
        
        # ä»åŸå§‹å›¾åƒæå–æˆªå›¾
        x1, y1, x2, y2 = capture_region
        captured_image = original_image[y1:y2, x1:x2].copy()
        
        # æ£€æŸ¥æˆªå›¾æ˜¯å¦æœ‰æ•ˆ
        if captured_image.size == 0:
            print("âŒ æˆªå›¾åŒºåŸŸæ— æ•ˆï¼Œè·³è¿‡ä¿å­˜")
            self.last_capture_time = time.time()
            return False
        
        # ğŸ†• æ ¹æ®æƒ…æ„Ÿç±»å‹ç”Ÿæˆä¸åŒçš„æ–‡ä»¶å
        filename = self.generate_emotion_filename(capture_reason, emotion_score)
        filepath = os.path.join(self.save_directory, filename)
        
        success = cv2.imwrite(filepath, captured_image)
        
        if success:
            # ğŸ†• æ ¹æ®æ•æ‰åŸå› æ˜¾ç¤ºä¸åŒçš„emojiå’Œä¿¡æ¯
            emotion_emoji = {
                'happy': 'ğŸ˜Š',
                'surprise': 'ğŸ˜²',  # ğŸ†• æ–°å¢æƒŠè®¶è¡¨æƒ…
                'sad': 'ğŸ˜¢', 
                'angry': 'ğŸ˜ '
            }
            
            emoji = emotion_emoji.get(capture_reason, 'ğŸ˜')
            
            print(f"ğŸ“¸ æ•æ‰æƒ…æ„Ÿç¬é—´æˆåŠŸ!")
            print(f"   ğŸ‘¤ äººè„¸ID: {face_id}")
            print(f"   {emoji} æ•æ‰åŸå› : {capture_reason.upper()} ({emotion_score:.1f}%)")
            print(f"   ğŸ“ ä¿å­˜è·¯å¾„: {filepath}")
            print(f"   ğŸ“ æˆªå›¾å°ºå¯¸: {captured_image.shape[1]}x{captured_image.shape[0]}")
            print(f"   âœ¨ æˆªå›¾ç±»å‹: åŸå§‹å›¾åƒï¼ˆæ— ç»˜åˆ¶å†…å®¹ï¼‰")
            
            # ğŸ†• è°ƒç”¨æ‹ç…§å›è°ƒå‡½æ•°
            if self.photo_callback:
                photo_info = {
                    'face_id': face_id,
                    'emotion_type': capture_reason,
                    'emotion_score': emotion_score,
                    'filename': filename,
                    'filepath': filepath,
                    'capture_region': capture_region,
                    'image_size': captured_image.shape
                }
                self.photo_callback(photo_info)
            
            # ğŸ†• è‡ªåŠ¨è§¦å‘å›¾ç‰‡åˆæˆ - å·²ç¦ç”¨ï¼Œç”±æœåŠ¡å™¨ç«¯æ–°æµç¨‹æ§åˆ¶
            # self.image_composer.queue_composition(filepath, capture_reason)
            
            # ğŸ†• è®¾ç½®å¯è§†åŒ–æŒ‡ç¤ºå™¨
            self.last_capture_visual_indicator = True
            self.last_captured_person = target_person
            self.visual_indicator_start_time = time.time()
        else:
            print(f"âŒ ä¿å­˜æˆªå›¾å¤±è´¥: {filepath}")
        
        self.last_capture_time = time.time()
        return success
    
    def draw_capture_visual_on_display(self, display_image, current_faces_data):
        """
        åœ¨æ˜¾ç¤ºå›¾åƒä¸Šç»˜åˆ¶æ•æ‰çš„å¯è§†åŒ–æŒ‡ç¤º
        
        å‚æ•°:
            display_image: æ˜¾ç¤ºå›¾åƒï¼ˆå¯ä»¥ç»˜åˆ¶ï¼‰
            current_faces_data: å½“å‰äººè„¸æ•°æ®
        """
        if not self.last_capture_visual_indicator or not self.last_captured_person:
            return
        
        # æ‰¾åˆ°å¯¹åº”çš„äººè„¸
        captured_face_id = self.last_captured_person['face_id']
        captured_person = None
        
        for person_data in current_faces_data:
            if person_data['face_id'] == captured_face_id:
                captured_person = person_data
                break
        
        if not captured_person:
            return
        
        face_info = captured_person['face_info']
        capture_reason = self.last_captured_person['capture_reason']
        emotion_score = self.last_captured_person['emotion_score']
        
        # è®¡ç®—æ•æ‰åŒºåŸŸ
        capture_region = self.calculate_capture_region(
            face_info['bbox'], display_image.shape
        )
        
        # ğŸ†• æ ¹æ®æƒ…æ„Ÿç±»å‹é€‰æ‹©ä¸åŒçš„é¢œè‰²
        emotion_colors_capture = {
            'happy': (0, 255, 255),      # é»„è‰²
            'surprise': (255, 0, 255),   # ğŸ†• ç´«è‰² (æƒŠè®¶)
            'sad': (255, 0, 0),          # è“è‰²
            'angry': (0, 0, 255)         # çº¢è‰²
        }
        
        capture_color = emotion_colors_capture.get(capture_reason, (255, 255, 255))
        
        # ç»˜åˆ¶æ•æ‰æŒ‡ç¤º
        self.draw_capture_indicator(
            display_image, capture_region, captured_face_id,
            capture_reason, emotion_score, capture_color
        )
    
    def draw_capture_indicator(self, image, capture_region, face_id, 
                              emotion_type, emotion_score, color):
        """
        åœ¨åŸå›¾ä¸Šç»˜åˆ¶æ•æ‰æ ‡è¯†
        
        å‚æ•°:
            image: åŸå§‹å›¾åƒ
            capture_region: æˆªå›¾åŒºåŸŸ
            face_id: äººè„¸ID
            emotion_type: æƒ…æ„Ÿç±»å‹
            emotion_score: æƒ…æ„Ÿåˆ†æ•°
            color: æ˜¾ç¤ºé¢œè‰²
        """
        x1, y1, x2, y2 = capture_region
        
        # ğŸ†• é—ªçƒæ•ˆæœ
        current_time = time.time()
        blink_phase = int((current_time - self.visual_indicator_start_time) * 4) % 2
        
        if blink_phase == 0:
            # ç»˜åˆ¶æ•æ‰åŒºåŸŸæ¡†
            cv2.rectangle(image, (x1, y1), (x2, y2), color, 4)
            # ç»˜åˆ¶é—ªå…‰æ•ˆæœ
            cv2.rectangle(image, (x1+3, y1+3), (x2-3, y2-3), (255, 255, 255), 3)
        
        # ğŸ†• æ ¹æ®æƒ…æ„Ÿç±»å‹æ·»åŠ ä¸åŒçš„emojiæ–‡å­—
        emotion_emoji = {
            'happy': 'ğŸ˜Š',
            'surprise': 'ğŸ˜²',  # ğŸ†• æ–°å¢æƒŠè®¶è¡¨æƒ…
            'sad': 'ğŸ˜¢', 
            'angry': 'ğŸ˜ '
        }
        
        emoji = emotion_emoji.get(emotion_type, 'ğŸ˜')
        
        # æ·»åŠ æ–‡å­—æ ‡è¯†
        capture_text = f"ğŸ“¸ CAPTURED! {emoji} {emotion_type.upper()}"
        details_text = f"ID:{face_id} Score:{emotion_score:.1f}%"
        
        cv2.putText(image, capture_text, (x1, y1-30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
        cv2.putText(image, details_text, (x1, y1-10), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
        
        # æ·»åŠ "åŸå§‹å›¾åƒ"æ ‡è¯†
        original_text = "âœ¨ Original Image Saved"
        cv2.putText(image, original_text, (x1, y2+25), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
    
    def get_next_capture_countdown(self):
        """
        è·å–ä¸‹æ¬¡æ•æ‰çš„å€’è®¡æ—¶
        
        è¿”å›:
            float: å‰©ä½™ç§’æ•°
        """
        current_time = time.time()
        elapsed = current_time - self.last_capture_time
        remaining = max(0, self.capture_interval - elapsed)
        return remaining
    
    def draw_countdown_info(self, image):
        """
        åœ¨å›¾åƒä¸Šç»˜åˆ¶å€’è®¡æ—¶ä¿¡æ¯
        
        å‚æ•°:
            image: å›¾åƒ
        """
        countdown = self.get_next_capture_countdown()
        
        if countdown > 0:
            countdown_text = f"Next emotion capture in: {countdown:.1f}s"
            color = (100, 100, 100)  # ç°è‰²
        else:
            countdown_text = "Ready to capture emotions!"
            color = (0, 255, 0)  # ç»¿è‰²
        
        # ğŸ†• æ›´æ–°ä¼˜å…ˆçº§æç¤º
        priority_text = "Priority: Happy > Surprise > Sad > Angry"
        
        cv2.putText(image, countdown_text, (10, 90), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
        cv2.putText(image, priority_text, (10, 115), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1) 

    def shutdown(self):
        """å…³é—­ç®¡ç†å™¨"""
        if hasattr(self, 'image_composer'):
            self.image_composer.shutdown() 