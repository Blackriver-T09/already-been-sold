import os
import warnings

# æŠ‘åˆ¶TensorFlowè­¦å‘Š
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
warnings.filterwarnings('ignore')

import cv2
import mediapipe as mp
import numpy as np
import time
from deepface import DeepFace
import threading
from collections import deque, Counter

from utils import *
from config import *
from emotion_tracker import *


# å…¨å±€å˜é‡åˆå§‹åŒ–
emotion_cache = {}
emotion_lock = threading.Lock()
emotion_history = {}
history_lock = threading.Lock()

# è®¾ç½®æ˜¾ç¤ºçª—å£
cv2.namedWindow("Face Emotion Recognition System", cv2.WINDOW_NORMAL)

def get_emotion_data(matched_id):
    """
    è·å–æƒ…æ„Ÿæ•°æ®
    
    å‚æ•°:
        matched_id: äººè„¸ID
    
    è¿”å›:
        dict: æƒ…æ„Ÿæ•°æ®å­—å…¸
    """
    with emotion_lock:
        if matched_id in emotion_cache:
            emotion_data = emotion_cache[matched_id]
            
            emotion = emotion_data['dominant_emotion']
            score = emotion_data['dominant_score']
            all_emotions = emotion_data.get('all_emotions', {})
            
            emotion_text = f"{emotion.capitalize()}({score:.1f})"
            emotion_color = emotion_colors.get(emotion, (255, 255, 255))
            
            return {
                'emotion': emotion,
                'score': score,
                'text': emotion_text,
                'color': emotion_color,
                'all_emotions': all_emotions
            }
    
    return None

def reset_emotion_history(face_id):
    """é‡ç½®æƒ…æ„Ÿå†å²"""
    with history_lock:
        if face_id in emotion_history:
            emotion_history[face_id].clear()

def main():
    """ä¸»ç¨‹åºå…¥å£"""
    # åˆå§‹åŒ–å„ä¸ªç»„ä»¶
    face_db = FaceDatabase(similarity_threshold=0.85, position_threshold=100)
    emotion_scheduler = EmotionScheduler(update_interval=0.3)
    system_controller = SystemController(
        emotion_scheduler, face_db, emotion_cache, 
        emotion_history, emotion_lock, history_lock
    )
    
    # ğŸ”§ ä¿®æ”¹æŠ“æ‹é—´éš”ï¼š10ç§’ â†’ 30ç§’
    happy_capture = HappyCaptureManager(
        capture_interval=30,  # ğŸ†• ä»10æ”¹ä¸º30ç§’
        save_directory="pictures"
    )
    
    # ğŸ†• åˆå§‹åŒ–å›¾ç‰‡åˆæˆå™¨
    happy_capture.image_composer = ImageComposer(sources_dir="sources")
    
    # é…ç½®MediaPipe Face Meshå‚æ•°
    with mp_face_mesh.FaceMesh(
        max_num_faces=5,
        refine_landmarks=True,
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5
    ) as face_mesh:

        print("å¼€å§‹äººè„¸æƒ…æ„Ÿè¯†åˆ«...")
        
        try:
            while cap.isOpened() and system_controller.is_running():  # ğŸ”‘ ä¸»å¾ªç¯å¼€å§‹
                # è¯»å–æ‘„åƒå¤´å¸§
                success, frame = cap.read()
                if not success:
                    print("æ‘„åƒå¤´è¯»å–å¤±è´¥")
                    break
                
                # ğŸ†• ä¿å­˜åŸå§‹å›¾åƒï¼ˆç”¨äºæ— ç»˜åˆ¶çš„æˆªå›¾ï¼‰
                original_image = frame.copy()
                
                # ç¿»è½¬å›¾åƒ
                image = cv2.flip(frame, 1)
                original_image = cv2.flip(original_image, 1)  # åŒæ­¥ç¿»è½¬åŸå§‹å›¾åƒ
                
                # äººè„¸æ£€æµ‹
                results = BGR_RGB(image, face_mesh)
                detected_faces = process_detection_results(results, image.shape)
                        
                # æ”¶é›†å½“å‰å¸§çš„æ‰€æœ‰äººè„¸æ•°æ®
                current_faces_data = []
                
                # å¤„ç†æ¯å¼ æ£€æµ‹åˆ°çš„äººè„¸
                for face_info in detected_faces:
                    # äººè„¸åŒ¹é…
                    matched_id = process_face_matching(
                        face_info, face_db, reset_emotion_history
                    )
                    
                    # ğŸ¨ ç»˜åˆ¶äººè„¸ï¼ˆåœ¨æ˜¾ç¤ºå›¾åƒä¸Šï¼‰
                    draw_face(image, face_info['landmarks'])
                    
                    # æå–äººè„¸åŒºåŸŸï¼ˆä»åŸå§‹å›¾åƒï¼‰
                    face_img = extract_face_region(original_image, face_info['bbox'])
                    
                    # è°ƒåº¦æƒ…æ„Ÿåˆ†æ
                    emotion_scheduler.schedule_emotion_analysis(
                        matched_id, face_img, emotion_lock, emotion_cache, analyze_emotion
                    )
                    
                    # è·å–å’Œæ˜¾ç¤ºæƒ…æ„Ÿä¿¡æ¯
                    emotion_data = get_emotion_data(matched_id)
                    if emotion_data:
                        # æ”¶é›†äººè„¸æ•°æ®ç”¨äºå¿«ä¹ç¬é—´æ•æ‰
                        current_faces_data.append({
                            'face_id': matched_id,
                            'emotion_data': emotion_data,
                            'face_info': face_info
                        })
                        
                        # ğŸ¨ ç»˜åˆ¶æƒ…æ„Ÿä¿¡æ¯ï¼ˆåœ¨æ˜¾ç¤ºå›¾åƒä¸Šï¼‰
                        x, y, w, h = face_info['bbox']
                        draw_emotion_bars(
                            image, emotion_data['all_emotions'], x, y, h,
                            matched_id, emotion_data['text'], 
                            emotion_data['color'], emotion_colors
                        )
                        
                        # ğŸ¨ ç»˜åˆ¶è¾¹ç•Œæ¡†ï¼ˆåœ¨æ˜¾ç¤ºå›¾åƒä¸Šï¼‰
                        cv2.rectangle(image, (x, y), (x + w, y + h), emotion_data['color'], 2)
                        
                        # æ›´æ–°æƒ…æ„Ÿå˜åŒ–è®°å½•
                        emotion_scheduler.update_emotion_change(matched_id, emotion_data['emotion'])
                
                # ğŸ†• å°è¯•æ•æ‰å¿«ä¹ç¬é—´ï¼ˆä½¿ç”¨åŸå§‹å›¾åƒï¼‰
                happy_capture.capture_happy_moment(original_image, current_faces_data)
                    
                # ğŸ†• ç»˜åˆ¶æ•æ‰å€’è®¡æ—¶ä¿¡æ¯ï¼ˆåœ¨æ˜¾ç¤ºå›¾åƒä¸Šï¼‰
                happy_capture.draw_countdown_info(image)
                
                # ğŸ†• å¦‚æœåˆšåˆšæ•æ‰äº†ç…§ç‰‡ï¼Œåœ¨æ˜¾ç¤ºå›¾åƒä¸Šä¹Ÿæ˜¾ç¤ºæ•æ‰æŒ‡ç¤º
                if happy_capture.last_capture_visual_indicator:
                    happy_capture.draw_capture_visual_on_display(image, current_faces_data)
                
                # ç»˜åˆ¶ç³»ç»Ÿä¿¡æ¯
                system_controller.draw_system_info(image)
                    
                # ğŸ†• æ›´æ–°ç³»ç»Ÿæ§åˆ¶å™¨çš„å½“å‰æ•°æ®ï¼ˆä¾›æ‰‹åŠ¨æ•æ‰ä½¿ç”¨ï¼‰
                system_controller.update_current_data(original_image, current_faces_data)
            
                # æ˜¾ç¤ºå›¾åƒ
                cv2.imshow('Face Emotion Recognition System', image)
            
                # å¤„ç†é”®ç›˜è¾“å…¥
                key = cv2.waitKey(5) & 0xFF
                if not system_controller.handle_keyboard_input(key):
                    break  # ğŸ”‘ è¿™ä¸ªbreakç°åœ¨æ­£ç¡®åœ°åœ¨whileå¾ªç¯å†…éƒ¨
                    
            # ğŸ”‘ whileå¾ªç¯ç»“æŸ
        except KeyboardInterrupt:
            print("\nğŸ”„ ç¨‹åºä¸­æ–­ï¼Œæ­£åœ¨æ¸…ç†èµ„æº...")
        finally:
            # ğŸ†• å…³é—­åˆæˆå™¨
            happy_capture.shutdown()
            
            # é‡Šæ”¾èµ„æº
            cap.release()
            cv2.destroyAllWindows()

if __name__ == "__main__":
    main()