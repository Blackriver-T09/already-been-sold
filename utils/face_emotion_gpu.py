"""
GPUåŠ é€Ÿç‰ˆæœ¬çš„äººè„¸æƒ…ç»ªè¯†åˆ«æ¨¡å—
é’ˆå¯¹RTX 4070ä¼˜åŒ–çš„é«˜æ€§èƒ½ç‰ˆæœ¬
"""

import cv2
import mediapipe as mp
import numpy as np
import time
from deepface import DeepFace
import threading
from collections import deque, Counter
import tensorflow as tf
import torch

# å¯¼å…¥GPUé…ç½®ï¼ˆæ”¯æŒç›´æ¥è¿è¡Œå’Œæ¨¡å—å¯¼å…¥ï¼‰
try:
    from .gpu_config import setup_gpu_environment, get_optimal_deepface_config, monitor_gpu_usage
except ImportError:
    # ç›´æ¥è¿è¡Œæ—¶ä½¿ç”¨ç»å¯¹å¯¼å…¥
    from gpu_config import setup_gpu_environment, get_optimal_deepface_config, monitor_gpu_usage

# åˆå§‹åŒ–GPUç¯å¢ƒ
setup_gpu_environment()

# æƒ…æ„Ÿå†å²è®°å½• - ä¸ºæ¯ä¸ªäººè„¸ç»´æŠ¤å†å²
emotion_history = {}
history_lock = threading.Lock()

# GPUåŠ é€Ÿé…ç½®å‚æ•°
HISTORY_SIZE = 3
MIN_CONFIDENCE = 80
FAST_CHANGE_THRESHOLD = 1
STABLE_CHANGE_THRESHOLD = 2
INSTANT_RESPONSE_THRESHOLD = 70

# æƒ…æ„Ÿåå·®æ ¡æ­£é…ç½®ï¼ˆGPUä¼˜åŒ–ç‰ˆæœ¬ï¼‰
EMOTION_BIAS_CORRECTION = {
    'angry': 0.2,
    'happy': 1.2,
    'neutral': 12,
    'sad': 0.01,
    'surprise': 15,
    'fear': 0.001,
    'disgust': 4
}

class GPUEmotionAnalyzer:
    """
    GPUåŠ é€Ÿçš„æƒ…ç»ªåˆ†æå™¨
    """
    
    def __init__(self):
        """åˆå§‹åŒ–GPUæƒ…ç»ªåˆ†æå™¨"""
        print("ğŸš€ åˆå§‹åŒ–GPUåŠ é€Ÿæƒ…ç»ªåˆ†æå™¨...")
        
        # è·å–æœ€ä¼˜DeepFaceé…ç½®
        self.deepface_config = get_optimal_deepface_config()
        print(f"ğŸ“‹ DeepFaceé…ç½®: {self.deepface_config}")
        
        # é¢„åŠ è½½æ¨¡å‹åˆ°GPU
        self._preload_models()
        
        # åˆ›å»ºGPUå†…å­˜æ± ï¼ˆå¦‚æœæ”¯æŒï¼‰
        self._setup_gpu_memory_pool()
        
        print("âœ… GPUæƒ…ç»ªåˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _preload_models(self):
        """é¢„åŠ è½½æ¨¡å‹åˆ°GPUå†…å­˜"""
        try:
            print("ğŸ”„ é¢„åŠ è½½DeepFaceæ¨¡å‹åˆ°GPU...")
            
            # åˆ›å»ºä¸€ä¸ªå°çš„æµ‹è¯•å›¾åƒæ¥é¢„çƒ­æ¨¡å‹
            dummy_img = np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8)
            
            # é¢„çƒ­DeepFaceæ¨¡å‹ï¼ˆç§»é™¤ä¸å…¼å®¹å‚æ•°ï¼‰
            _ = DeepFace.analyze(
                dummy_img, 
                actions=['emotion'],
                detector_backend=self.deepface_config['detector_backend'],
                enforce_detection=False
            )
            
            print("âœ… DeepFaceæ¨¡å‹é¢„åŠ è½½å®Œæˆ")
            
        except Exception as e:
            print(f"âš ï¸ æ¨¡å‹é¢„åŠ è½½å¤±è´¥ï¼Œå°†åœ¨é¦–æ¬¡ä½¿ç”¨æ—¶åŠ è½½: {e}")
    
    def _setup_gpu_memory_pool(self):
        """è®¾ç½®GPUå†…å­˜æ± ä¼˜åŒ–"""
        try:
            # TensorFlow GPUå†…å­˜ä¼˜åŒ–
            gpus = tf.config.experimental.list_physical_devices('GPU')
            if gpus:
                # è®¾ç½®å†…å­˜å¢é•¿
                for gpu in gpus:
                    tf.config.experimental.set_memory_growth(gpu, True)
                
                # è®¾ç½®è™šæ‹ŸGPUè®¾å¤‡ï¼ˆå¯é€‰ï¼‰
                tf.config.experimental.set_virtual_device_configuration(
                    gpus[0],
                    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=6144)]  # 6GBé™åˆ¶
                )
                
            print("âœ… GPUå†…å­˜æ± é…ç½®å®Œæˆ")
            
        except Exception as e:
            print(f"âš ï¸ GPUå†…å­˜æ± é…ç½®å¤±è´¥: {e}")
    
    def analyze_emotion_gpu(self, face_id, face_img, emotion_lock, emotion_cache):
        """
        GPUåŠ é€Ÿçš„æƒ…ç»ªåˆ†æå‡½æ•°
        """
        try:
            if face_img.size == 0:
                return
            
            # GPUåŠ é€Ÿçš„å›¾åƒé¢„å¤„ç†
            face_img_processed = self._gpu_preprocess_image(face_img)
            
            # ä½¿ç”¨GPUè¿›è¡ŒDeepFaceåˆ†æï¼ˆç§»é™¤ä¸å…¼å®¹çš„å‚æ•°ï¼‰
            with tf.device('/GPU:0'):  # å¼ºåˆ¶ä½¿ç”¨GPU
                result = DeepFace.analyze(
                    face_img_processed, 
                    actions=['emotion'],
                    detector_backend=self.deepface_config['detector_backend'],
                    enforce_detection=self.deepface_config['enforce_detection']
                    # æ³¨æ„ï¼šmodel_name, align, normalization å‚æ•°åœ¨å½“å‰ç‰ˆæœ¬ä¸­ä¸è¢«æ”¯æŒï¼Œå·²ç§»é™¤
                )
            
            if isinstance(result, list):
                result = result[0]
            
            # è·å–åŸå§‹åˆ†æç»“æœ
            raw_emotion = result['dominant_emotion']
            raw_score = result['emotion'][raw_emotion]
            
            # åº”ç”¨åå·®æ ¡æ­£
            corrected_emotions = self._correct_emotion_bias_gpu(result['emotion'])
            
            # é‡æ–°æ‰¾å‡ºæ ¡æ­£åçš„ä¸»å¯¼æƒ…æ„Ÿ
            corrected_dominant = max(corrected_emotions.items(), key=lambda x: x[1])
            corrected_emotion = corrected_dominant[0]
            corrected_score = corrected_dominant[1]
            
            # åº”ç”¨æƒ…æ„Ÿå¹³æ»‘ç®—æ³•
            stable_emotion, stable_score = self._smooth_emotion_gpu(face_id, corrected_emotion, corrected_score)
            
            # çº¿ç¨‹å®‰å…¨åœ°æ›´æ–°æƒ…æ„Ÿç¼“å­˜
            with emotion_lock:
                emotion_cache[face_id] = {
                    'dominant_emotion': stable_emotion,
                    'dominant_score': stable_score,
                    'all_emotions': corrected_emotions,
                    'raw_emotion': raw_emotion,
                    'raw_score': raw_score,
                    'corrected_emotion': corrected_emotion,
                    'corrected_score': corrected_score,
                    'processing_device': 'GPU'  # æ ‡è®°ä½¿ç”¨äº†GPU
                }
            
            # å¯é€‰ï¼šæ˜¾ç¤ºGPUå¤„ç†ä¿¡æ¯
            # print(f"ğŸš€ GPUå¤„ç† ID{face_id}: {raw_emotion}â†’{stable_emotion}({stable_score:.1f})")
            
        except Exception as e:
            print(f"âŒ GPUæƒ…æ„Ÿåˆ†æé”™è¯¯: {e}")
            # é™çº§åˆ°CPUå¤„ç†
            self._fallback_to_cpu_analysis(face_id, face_img, emotion_lock, emotion_cache)
    
    def _gpu_preprocess_image(self, face_img):
        """
        GPUåŠ é€Ÿçš„å›¾åƒé¢„å¤„ç†
        """
        try:
            # ä½¿ç”¨OpenCV GPUå‡½æ•°ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if cv2.cuda.getCudaEnabledDeviceCount() > 0:
                # ä¸Šä¼ åˆ°GPU
                gpu_img = cv2.cuda_GpuMat()
                gpu_img.upload(face_img)
                
                # GPUä¸Šè°ƒæ•´å¤§å°
                gpu_resized = cv2.cuda.resize(gpu_img, (224, 224))
                
                # GPUä¸Šçš„ç›´æ–¹å›¾å‡è¡¡åŒ–
                if len(face_img.shape) == 3:
                    gpu_yuv = cv2.cuda.cvtColor(gpu_resized, cv2.COLOR_BGR2YUV)
                    # æ³¨æ„ï¼šCUDAç‰ˆæœ¬çš„equalizeHistå¯èƒ½éœ€è¦ä¸åŒçš„API
                    
                # ä¸‹è½½å›CPU
                result = gpu_resized.download()
                
                return result
            else:
                # é™çº§åˆ°CPUå¤„ç†
                return self._cpu_preprocess_image(face_img)
                
        except Exception as e:
            print(f"âš ï¸ GPUå›¾åƒé¢„å¤„ç†å¤±è´¥ï¼Œé™çº§åˆ°CPU: {e}")
            return self._cpu_preprocess_image(face_img)
    
    def _cpu_preprocess_image(self, face_img):
        """
        CPUç‰ˆæœ¬çš„å›¾åƒé¢„å¤„ç†ï¼ˆå¤‡é€‰æ–¹æ¡ˆï¼‰
        """
        # è°ƒæ•´å¤§å°
        face_img_resized = cv2.resize(face_img, (224, 224))
        
        # ç›´æ–¹å›¾å‡è¡¡åŒ–
        if len(face_img_resized.shape) == 3:
            yuv = cv2.cvtColor(face_img_resized, cv2.COLOR_BGR2YUV)
            yuv[:,:,0] = cv2.equalizeHist(yuv[:,:,0])
            enhanced = cv2.cvtColor(yuv, cv2.COLOR_YUV2BGR)
        else:
            enhanced = cv2.equalizeHist(face_img_resized)
        
        # è½»å¾®é«˜æ–¯æ¨¡ç³Š
        enhanced = cv2.GaussianBlur(enhanced, (3, 3), 0)
        
        return enhanced
    
    def _correct_emotion_bias_gpu(self, emotion_probs):
        """
        GPUä¼˜åŒ–çš„æƒ…æ„Ÿåå·®æ ¡æ­£
        """
        # ä½¿ç”¨TensorFlowåœ¨GPUä¸Šè¿›è¡Œå‘é‡åŒ–è®¡ç®—
        try:
            with tf.device('/GPU:0'):
                # è½¬æ¢ä¸ºTensorFlowå¼ é‡
                emotions = list(emotion_probs.keys())
                probs = tf.constant([emotion_probs[emo] for emo in emotions], dtype=tf.float32)
                corrections = tf.constant([EMOTION_BIAS_CORRECTION.get(emo, 1.0) for emo in emotions], dtype=tf.float32)
                
                # å‘é‡åŒ–æ ¡æ­£
                corrected_probs = probs * corrections
                
                # é‡æ–°å½’ä¸€åŒ–
                total = tf.reduce_sum(corrected_probs)
                normalized_probs = (corrected_probs / total) * 100.0
                
                # è½¬æ¢å›å­—å…¸
                result = {}
                for i, emotion in enumerate(emotions):
                    result[emotion] = float(normalized_probs[i])
                
                return result
                
        except Exception as e:
            print(f"âš ï¸ GPUåå·®æ ¡æ­£å¤±è´¥ï¼Œä½¿ç”¨CPU: {e}")
            return self._correct_emotion_bias_cpu(emotion_probs)
    
    def _correct_emotion_bias_cpu(self, emotion_probs):
        """
        CPUç‰ˆæœ¬çš„æƒ…æ„Ÿåå·®æ ¡æ­£
        """
        corrected = {}
        for emotion, prob in emotion_probs.items():
            correction_factor = EMOTION_BIAS_CORRECTION.get(emotion, 1.0)
            corrected[emotion] = prob * correction_factor
        
        # é‡æ–°å½’ä¸€åŒ–
        total = sum(corrected.values())
        if total > 0:
            for emotion in corrected:
                corrected[emotion] = (corrected[emotion] / total) * 100
        
        return corrected
    
    def _smooth_emotion_gpu(self, face_id, new_emotion, new_score):
        """
        GPUä¼˜åŒ–çš„æƒ…æ„Ÿå¹³æ»‘ç®—æ³•
        """
        # æƒ…æ„Ÿå¹³æ»‘é€»è¾‘ä¿æŒä¸å˜ï¼Œä½†å¯ä»¥è€ƒè™‘GPUåŠ é€ŸæŸäº›è®¡ç®—
        with history_lock:
            if face_id not in emotion_history:
                emotion_history[face_id] = deque(maxlen=HISTORY_SIZE)
            
            if new_score >= MIN_CONFIDENCE:
                emotion_history[face_id].append((new_emotion, new_score))
            
            if len(emotion_history[face_id]) < 1:
                return new_emotion, new_score
            
            if new_score >= INSTANT_RESPONSE_THRESHOLD:
                return new_emotion, new_score
            
            recent_emotions = [emotion for emotion, score in emotion_history[face_id]]
            
            if len(recent_emotions) == 1:
                return new_emotion, new_score
            
            emotion_counts = Counter(recent_emotions)
            most_common_emotion = emotion_counts.most_common(1)[0][0]
            most_common_count = emotion_counts.most_common(1)[0][1]
            
            # è®¡ç®—å¹³å‡ç½®ä¿¡åº¦
            scores = [score for emotion, score in emotion_history[face_id] 
                     if emotion == most_common_emotion]
            avg_score = sum(scores) / len(scores) if scores else new_score
            
            return most_common_emotion, avg_score
    
    def _fallback_to_cpu_analysis(self, face_id, face_img, emotion_lock, emotion_cache):
        """
        GPUå¤±è´¥æ—¶çš„CPUé™çº§å¤„ç†
        """
        try:
            print(f"ğŸ”„ GPUå¤„ç†å¤±è´¥ï¼Œé™çº§åˆ°CPUå¤„ç† (ID: {face_id})")
            
            # ä½¿ç”¨CPUç‰ˆæœ¬çš„DeepFace
            face_img_resized = cv2.resize(face_img, (224, 224))
            
            result = DeepFace.analyze(
                face_img_resized, 
                actions=['emotion'],
                detector_backend='opencv',  # CPUå‹å¥½çš„æ£€æµ‹å™¨
                enforce_detection=False
            )
            
            if isinstance(result, list):
                result = result[0]
            
            raw_emotion = result['dominant_emotion']
            raw_score = result['emotion'][raw_emotion]
            
            with emotion_lock:
                emotion_cache[face_id] = {
                    'dominant_emotion': raw_emotion,
                    'dominant_score': raw_score,
                    'all_emotions': result['emotion'],
                    'raw_emotion': raw_emotion,
                    'raw_score': raw_score,
                    'processing_device': 'CPU'  # æ ‡è®°ä½¿ç”¨äº†CPU
                }
                
        except Exception as e:
            print(f"âŒ CPUé™çº§å¤„ç†ä¹Ÿå¤±è´¥: {e}")
            with emotion_lock:
                emotion_cache[face_id] = {
                    'dominant_emotion': "unknown",
                    'dominant_score': 0,
                    'all_emotions': {},
                    'processing_device': 'ERROR'
                }
    
    def get_performance_stats(self):
        """
        è·å–GPUæ€§èƒ½ç»Ÿè®¡
        """
        stats = {
            'gpu_available': len(tf.config.experimental.list_physical_devices('GPU')) > 0,
            'cuda_available': torch.cuda.is_available() if 'torch' in globals() else False,
            'opencv_cuda': cv2.cuda.getCudaEnabledDeviceCount() > 0,
            'deepface_config': self.deepface_config
        }
        
        # æ·»åŠ GPUå†…å­˜ä½¿ç”¨æƒ…å†µ
        try:
            if torch.cuda.is_available():
                stats['gpu_memory_allocated'] = torch.cuda.memory_allocated() / 1024**2  # MB
                stats['gpu_memory_reserved'] = torch.cuda.memory_reserved() / 1024**2   # MB
        except:
            pass
            
        return stats

# å…¨å±€GPUæƒ…ç»ªåˆ†æå™¨å®ä¾‹
gpu_emotion_analyzer = GPUEmotionAnalyzer()

def analyze_emotion_gpu(face_id, face_img, emotion_lock, emotion_cache):
    """
    GPUåŠ é€Ÿæƒ…ç»ªåˆ†æçš„å…¨å±€æ¥å£å‡½æ•°
    """
    return gpu_emotion_analyzer.analyze_emotion_gpu(face_id, face_img, emotion_lock, emotion_cache)

def get_gpu_performance_stats():
    """
    è·å–GPUæ€§èƒ½ç»Ÿè®¡çš„å…¨å±€æ¥å£
    """
    return gpu_emotion_analyzer.get_performance_stats()

if __name__ == "__main__":
    # æµ‹è¯•GPUæƒ…ç»ªåˆ†æå™¨
    print("ğŸ§ª æµ‹è¯•GPUæƒ…ç»ªåˆ†æå™¨...")
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    test_img = np.random.randint(0, 255, (100, 100, 3), dtype=np.uint8)
    
    # æµ‹è¯•åˆ†æ
    import threading
    emotion_cache = {}
    emotion_lock = threading.Lock()
    
    start_time = time.time()
    analyze_emotion_gpu("test_face", test_img, emotion_lock, emotion_cache)
    end_time = time.time()
    
    print(f"â±ï¸ GPUå¤„ç†æ—¶é—´: {(end_time - start_time)*1000:.2f}ms")
    print(f"ğŸ“Š åˆ†æç»“æœ: {emotion_cache}")
    print(f"ğŸ”§ æ€§èƒ½ç»Ÿè®¡: {get_gpu_performance_stats()}")
