import cv2
import os
import time
from datetime import datetime
import numpy as np

class HappyCaptureManager:
    """å¿«ä¹ç¬é—´æ•æ‰ç®¡ç†å™¨"""
    
    def __init__(self, capture_interval=10, save_directory="pictures"):
        """
        åˆå§‹åŒ–æ•æ‰ç®¡ç†å™¨
        
        å‚æ•°:
            capture_interval: æ•æ‰é—´éš”ï¼ˆç§’ï¼‰
            save_directory: ä¿å­˜ç›®å½•
        """
        self.capture_interval = capture_interval
        self.save_directory = save_directory
        self.last_capture_time = 0
        self.capture_count = 0
        
        # ğŸ†• å¯è§†åŒ–æŒ‡ç¤ºå™¨
        self.last_capture_visual_indicator = False
        self.last_captured_person = None
        self.visual_indicator_start_time = 0
        self.visual_indicator_duration = 3.0  # æ˜¾ç¤º3ç§’
        
        # ç¡®ä¿ä¿å­˜ç›®å½•å­˜åœ¨
        self.ensure_directory_exists()
    
    def ensure_directory_exists(self):
        """ç¡®ä¿ä¿å­˜ç›®å½•å­˜åœ¨"""
        if not os.path.exists(self.save_directory):
            os.makedirs(self.save_directory)
            print(f"ğŸ“ åˆ›å»ºç›®å½•: {self.save_directory}")
    
    def should_capture_now(self):
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥æ‰§è¡Œæ•æ‰
        
        è¿”å›:
            bool: æ˜¯å¦åº”è¯¥æ•æ‰
        """
        current_time = time.time()
        if current_time - self.last_capture_time >= self.capture_interval:
            return True
        return False
    
    def find_happiest_person(self, detected_faces_data):
        """
        æ‰¾åˆ°æœ€å¿«ä¹çš„äºº
        
        å‚æ•°:
            detected_faces_data: æ£€æµ‹åˆ°çš„äººè„¸æ•°æ®åˆ—è¡¨
            æ ¼å¼: [{'face_id': int, 'emotion_data': dict, 'face_info': dict}, ...]
        
        è¿”å›:
            dict: æœ€å¿«ä¹çš„äººçš„ä¿¡æ¯ï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ™è¿”å›None
        """
        if not detected_faces_data:
            return None
        
        happiest_person = None
        max_happy_score = 0
        
        for person_data in detected_faces_data:
            emotion_data = person_data.get('emotion_data')
            if not emotion_data:
                continue
            
            all_emotions = emotion_data.get('all_emotions', {})
            happy_score = all_emotions.get('happy', 0)
            
            # åªè€ƒè™‘happyæƒ…æ„Ÿæ˜æ˜¾çš„äººï¼ˆé¿å…ä¸­æ€§è¡¨æƒ…ï¼‰
            if happy_score > max_happy_score and happy_score > 20:  # è‡³å°‘20%çš„happy
                max_happy_score = happy_score
                happiest_person = person_data
        
        return happiest_person
    
    def calculate_capture_region(self, face_bbox, image_shape, scale_factor=3.0):
        """
        è®¡ç®—æˆªå›¾åŒºåŸŸï¼ˆ1:1æ­£æ–¹å½¢ï¼Œè¦†ç›–åˆ°èƒ¸å£ï¼‰
        
        å‚æ•°:
            face_bbox: äººè„¸è¾¹ç•Œæ¡† (x, y, w, h)
            image_shape: å›¾åƒå°ºå¯¸ (height, width, channels)
            scale_factor: ç¼©æ”¾å› å­ï¼Œæ§åˆ¶æˆªå›¾å¤§å°
        
        è¿”å›:
            tuple: (x1, y1, x2, y2) æˆªå›¾åŒºåŸŸåæ ‡
        """
        x, y, w, h = face_bbox
        image_height, image_width = image_shape[:2]
        
        # è®¡ç®—äººè„¸ä¸­å¿ƒç‚¹
        face_center_x = x + w // 2
        face_center_y = y + h // 2
        
        # è®¡ç®—æ­£æ–¹å½¢çš„è¾¹é•¿ï¼ˆåŸºäºäººè„¸é«˜åº¦çš„å€æ•°ï¼‰
        square_size = int(h * scale_factor)
        
        # ç¡®ä¿æ­£æ–¹å½¢æ˜¯å¥‡æ•°ï¼Œä¾¿äºä¸­å¿ƒå¯¹é½
        if square_size % 2 == 0:
            square_size += 1
        
        half_size = square_size // 2
        
        # è®¡ç®—æ­£æ–¹å½¢çš„è¾¹ç•Œ
        x1 = max(0, face_center_x - half_size)
        y1 = max(0, face_center_y - half_size)
        x2 = min(image_width, face_center_x + half_size)
        y2 = min(image_height, face_center_y + half_size)
        
        # ç¡®ä¿æ˜¯æ­£æ–¹å½¢ï¼ˆè°ƒæ•´åˆ°æœ€å°çš„å°ºå¯¸ï¼‰
        width = x2 - x1
        height = y2 - y1
        min_size = min(width, height)
        
        # é‡æ–°è®¡ç®—æ­£æ–¹å½¢è¾¹ç•Œ
        x1 = face_center_x - min_size // 2
        y1 = face_center_y - min_size // 2
        x2 = x1 + min_size
        y2 = y1 + min_size
        
        # æœ€ç»ˆè¾¹ç•Œæ£€æŸ¥
        x1 = max(0, x1)
        y1 = max(0, y1)
        x2 = min(image_width, x2)
        y2 = min(image_height, y2)
        
        return (x1, y1, x2, y2)
    
    def generate_filename(self):
        """
        ç”Ÿæˆæ–‡ä»¶å
        
        è¿”å›:
            str: æ–‡ä»¶å
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.capture_count += 1
        filename = f"happy_moment_{timestamp}_{self.capture_count:04d}.jpg"
        return filename
    
    def capture_happy_moment(self, original_image, detected_faces_data):
        """
        æ•æ‰å¿«ä¹ç¬é—´ï¼ˆä½¿ç”¨åŸå§‹å›¾åƒï¼‰
        
        å‚æ•°:
            original_image: åŸå§‹å›¾åƒï¼ˆæ— ä»»ä½•ç»˜åˆ¶ï¼‰
            detected_faces_data: æ£€æµ‹åˆ°çš„äººè„¸æ•°æ®åˆ—è¡¨
        
        è¿”å›:
            bool: æ˜¯å¦æˆåŠŸæ•æ‰
        """
        # é‡ç½®å¯è§†åŒ–æŒ‡ç¤ºå™¨ï¼ˆå¦‚æœè¶…æ—¶ï¼‰
        if (self.last_capture_visual_indicator and 
            time.time() - self.visual_indicator_start_time > self.visual_indicator_duration):
            self.last_capture_visual_indicator = False
            self.last_captured_person = None
        
        if not self.should_capture_now():
            return False
        
        # æ‰¾åˆ°æœ€å¿«ä¹çš„äºº
        happiest_person = self.find_happiest_person(detected_faces_data)
        if not happiest_person:
            print("âš ï¸ æœªæ‰¾åˆ°è¶³å¤Ÿå¿«ä¹çš„äººï¼Œè·³è¿‡æ•æ‰")
            self.last_capture_time = time.time()  # æ›´æ–°æ—¶é—´ï¼Œé¿å…é¢‘ç¹æ£€æŸ¥
            return False
        
        face_info = happiest_person['face_info']
        emotion_data = happiest_person['emotion_data']
        face_id = happiest_person['face_id']
        
        # è®¡ç®—æˆªå›¾åŒºåŸŸ
        capture_region = self.calculate_capture_region(
            face_info['bbox'], original_image.shape  # ğŸ†• ä½¿ç”¨åŸå§‹å›¾åƒçš„å°ºå¯¸
        )
        
        # ğŸ†• ä»åŸå§‹å›¾åƒæå–æˆªå›¾
        x1, y1, x2, y2 = capture_region
        captured_image = original_image[y1:y2, x1:x2].copy()
        
        # æ£€æŸ¥æˆªå›¾æ˜¯å¦æœ‰æ•ˆ
        if captured_image.size == 0:
            print("âŒ æˆªå›¾åŒºåŸŸæ— æ•ˆï¼Œè·³è¿‡ä¿å­˜")
            self.last_capture_time = time.time()
            return False
        
        # ç”Ÿæˆæ–‡ä»¶åå¹¶ä¿å­˜
        filename = self.generate_filename()
        filepath = os.path.join(self.save_directory, filename)
        
        success = cv2.imwrite(filepath, captured_image)
        
        if success:
            happy_score = emotion_data['all_emotions'].get('happy', 0)
            print(f"ğŸ“¸ æ•æ‰å¿«ä¹ç¬é—´æˆåŠŸ!")
            print(f"   ğŸ‘¤ äººè„¸ID: {face_id}")
            print(f"   ğŸ˜Š å¿«ä¹ç¨‹åº¦: {happy_score:.1f}%")
            print(f"   ğŸ“ ä¿å­˜è·¯å¾„: {filepath}")
            print(f"   ğŸ“ æˆªå›¾å°ºå¯¸: {captured_image.shape[1]}x{captured_image.shape[0]}")
            print(f"   âœ¨ æˆªå›¾ç±»å‹: åŸå§‹å›¾åƒï¼ˆæ— ç»˜åˆ¶å†…å®¹ï¼‰")
            
            # ğŸ†• è®¾ç½®å¯è§†åŒ–æŒ‡ç¤ºå™¨
            self.last_capture_visual_indicator = True
            self.last_captured_person = happiest_person
            self.visual_indicator_start_time = time.time()
        else:
            print(f"âŒ ä¿å­˜æˆªå›¾å¤±è´¥: {filepath}")
        
        self.last_capture_time = time.time()
        return success
    
    def draw_capture_visual_on_display(self, display_image, current_faces_data):
        """
        åœ¨æ˜¾ç¤ºå›¾åƒä¸Šç»˜åˆ¶æ•æ‰çš„å¯è§†åŒ–æŒ‡ç¤º
        
        å‚æ•°:
            display_image: æ˜¾ç¤ºå›¾åƒï¼ˆå¯ä»¥ç»˜åˆ¶ï¼‰
            current_faces_data: å½“å‰äººè„¸æ•°æ®
        """
        if not self.last_capture_visual_indicator or not self.last_captured_person:
            return
        
        # æ‰¾åˆ°å¯¹åº”çš„äººè„¸
        captured_face_id = self.last_captured_person['face_id']
        captured_person = None
        
        for person_data in current_faces_data:
            if person_data['face_id'] == captured_face_id:
                captured_person = person_data
                break
        
        if not captured_person:
            return
        
        face_info = captured_person['face_info']
        emotion_data = captured_person['emotion_data']
        
        # è®¡ç®—æ•æ‰åŒºåŸŸ
        capture_region = self.calculate_capture_region(
            face_info['bbox'], display_image.shape
        )
        
        # ç»˜åˆ¶æ•æ‰æŒ‡ç¤º
        self.draw_capture_indicator(
            display_image, capture_region, captured_face_id,
            emotion_data['all_emotions'].get('happy', 0)
        )
    
    def draw_capture_indicator(self, image, capture_region, face_id, happy_score):
        """
        åœ¨åŸå›¾ä¸Šç»˜åˆ¶æ•æ‰æ ‡è¯†
        
        å‚æ•°:
            image: åŸå§‹å›¾åƒ
            capture_region: æˆªå›¾åŒºåŸŸ
            face_id: äººè„¸ID
            happy_score: å¿«ä¹åˆ†æ•°
        """
        x1, y1, x2, y2 = capture_region
        
        # ğŸ†• é—ªçƒæ•ˆæœ
        current_time = time.time()
        blink_phase = int((current_time - self.visual_indicator_start_time) * 4) % 2
        
        if blink_phase == 0:
            # ç»˜åˆ¶æ•æ‰åŒºåŸŸæ¡†
            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 255), 4)  # é»„è‰²æ¡†
            # ç»˜åˆ¶é—ªå…‰æ•ˆæœ
            cv2.rectangle(image, (x1+3, y1+3), (x2-3, y2-3), (255, 255, 255), 3)  # ç™½è‰²å†…æ¡†
        
        # æ·»åŠ æ–‡å­—æ ‡è¯†
        capture_text = f"ğŸ“¸ CAPTURED! ID:{face_id} Happy:{happy_score:.1f}%"
        cv2.putText(image, capture_text, (x1, y1-15), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
        
        # æ·»åŠ "åŸå§‹å›¾åƒ"æ ‡è¯†
        original_text = "âœ¨ Original Image Saved"
        cv2.putText(image, original_text, (x1, y2+25), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
    
    def get_next_capture_countdown(self):
        """
        è·å–ä¸‹æ¬¡æ•æ‰çš„å€’è®¡æ—¶
        
        è¿”å›:
            float: å‰©ä½™ç§’æ•°
        """
        current_time = time.time()
        elapsed = current_time - self.last_capture_time
        remaining = max(0, self.capture_interval - elapsed)
        return remaining
    
    def draw_countdown_info(self, image):
        """
        åœ¨å›¾åƒä¸Šç»˜åˆ¶å€’è®¡æ—¶ä¿¡æ¯
        
        å‚æ•°:
            image: å›¾åƒ
        """
        countdown = self.get_next_capture_countdown()
        
        if countdown > 0:
            countdown_text = f"Next capture in: {countdown:.1f}s"
            color = (100, 100, 100)  # ç°è‰²
        else:
            countdown_text = "Ready to capture!"
            color = (0, 255, 0)  # ç»¿è‰²
        
        cv2.putText(image, countdown_text, (10, 90), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

class SystemController:
    """ç³»ç»Ÿæ§åˆ¶å™¨"""
    
    def __init__(self, emotion_scheduler, face_db, emotion_cache, emotion_history, 
                 emotion_lock, history_lock, happy_capture=None):
        self.emotion_scheduler = emotion_scheduler
        self.face_db = face_db
        self.emotion_cache = emotion_cache
        self.emotion_history = emotion_history
        self.emotion_lock = emotion_lock
        self.history_lock = history_lock
        self.running = True
        self.happy_capture = happy_capture
        self.current_faces_data = []  # ğŸ†• å­˜å‚¨å½“å‰äººè„¸æ•°æ®
        self.current_original_image = None  # ğŸ†• å­˜å‚¨å½“å‰åŸå§‹å›¾åƒ
    
    def update_current_data(self, original_image, faces_data):
        """
        æ›´æ–°å½“å‰æ•°æ®ï¼ˆä¾›æ‰‹åŠ¨æ•æ‰ä½¿ç”¨ï¼‰
        
        å‚æ•°:
            original_image: åŸå§‹å›¾åƒ
            faces_data: äººè„¸æ•°æ®
        """
        self.current_original_image = original_image.copy()
        self.current_faces_data = faces_data.copy()
    
    def handle_keyboard_input(self, key):
        """
        å¤„ç†é”®ç›˜è¾“å…¥
        
        å‚æ•°:
            key: æŒ‰é”®ç 
        
        è¿”å›:
            bool: æ˜¯å¦ç»§ç»­è¿è¡Œ
        """
        if key == 27:  # ESCé”®é€€å‡º
            self.running = False
            return False
        elif key == ord('r'):  # æŒ‰Ré”®é‡ç½®æ‰€æœ‰æ•°æ®
            self.reset_all_data()
        elif key == ord('c'):  # ğŸ†• æŒ‰Cé”®æ‰‹åŠ¨æ•æ‰åŸå§‹å›¾åƒ
            if self.happy_capture and self.current_original_image is not None:
                print("ğŸ“¸ æ‰‹åŠ¨è§¦å‘å¿«ä¹ç¬é—´æ•æ‰ï¼ˆåŸå§‹å›¾åƒï¼‰...")
                # å¼ºåˆ¶æ•æ‰ï¼ˆç»•è¿‡æ—¶é—´é™åˆ¶ï¼‰
                original_interval = self.happy_capture.capture_interval
                self.happy_capture.capture_interval = 0
                success = self.happy_capture.capture_happy_moment(
                    self.current_original_image, self.current_faces_data
                )
                self.happy_capture.capture_interval = original_interval
                
                if success:
                    print("âœ… æ‰‹åŠ¨æ•æ‰æˆåŠŸï¼")
                else:
                    print("âŒ æ‰‹åŠ¨æ•æ‰å¤±è´¥æˆ–æœªæ‰¾åˆ°å¿«ä¹çš„äººè„¸")
        elif key == ord('1'):  # æ•æ„Ÿåº¦æ§åˆ¶
            print("ğŸŒ æ•æ„Ÿåº¦: ä¿å®ˆæ¨¡å¼")
        elif key == ord('2'):
            print("âš–ï¸ æ•æ„Ÿåº¦: å¹³è¡¡æ¨¡å¼")
        elif key == ord('3'):
            print("âš¡ æ•æ„Ÿåº¦: çµæ•æ¨¡å¼")
        elif key == ord('4'):
            print("ğŸš€ æ•æ„Ÿåº¦: æåº¦çµæ•æ¨¡å¼")
        
        return True
    
    def reset_all_data(self):
        """é‡ç½®æ‰€æœ‰æ•°æ®"""
        print("ğŸ”„ é‡ç½®æ‰€æœ‰æ•°æ®")
        
        # é‡ç½®æƒ…æ„Ÿæ•°æ®
        with self.history_lock:
            self.emotion_history.clear()
        with self.emotion_lock:
            self.emotion_cache.clear()
        
        # é‡ç½®äººè„¸æ•°æ®åº“
        self.face_db.clear()
        
        # é‡ç½®è°ƒåº¦å™¨
        self.emotion_scheduler.reset()
    
    def draw_system_info(self, image):
        """
        ç»˜åˆ¶ç³»ç»Ÿä¿¡æ¯
        
        å‚æ•°:
            image: å›¾åƒ
        """
        cv2.putText(image, "Keys: C (manual capture), R (reset), ESC (exit)", 
                   (10, image.shape[0] - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
    
    def is_running(self):
        """æ£€æŸ¥ç³»ç»Ÿæ˜¯å¦ç»§ç»­è¿è¡Œ"""
        return self.running 