import cv2
import numpy as np
import base64
import time
import threading
import socketio
import json
from queue import Queue, Empty
import pygame  # ğŸ†• æ·»åŠ éŸ³é¢‘æ’­æ”¾åº“
import os

class FaceEmotionClient:
    """äººè„¸æƒ…æ„Ÿè¯†åˆ«WebSocketå®¢æˆ·ç«¯"""
    
    def __init__(self, server_url='http://test2.heihet09.com'):
        """
        åˆå§‹åŒ–å®¢æˆ·ç«¯
        
        å‚æ•°:
            server_url: æœåŠ¡å™¨åœ°å€
        """
        self.server_url = server_url
        
        # Socket.IOå®¢æˆ·ç«¯é…ç½® - ğŸ†• HTTPéš§é“ä¼˜åŒ– + ğŸ§ Ubuntuå…¼å®¹æ€§
        self.sio = socketio.Client(
            logger=False,
            engineio_logger=False,
            reconnection=True,
            reconnection_attempts=10,      # å¢åŠ é‡è¿æ¬¡æ•°
            reconnection_delay=2,          # å¢åŠ é‡è¿å»¶è¿Ÿ
            reconnection_delay_max=10,     # å¢åŠ æœ€å¤§é‡è¿å»¶è¿Ÿ
            # HTTPéš§é“ä¼˜åŒ–é…ç½®
            request_timeout=60,            # å¢åŠ è¯·æ±‚è¶…æ—¶
            # ğŸ§ Ubuntuå…¼å®¹æ€§é…ç½®
            http_session=None,             # é¿å…ä¼šè¯å†²çª
            ssl_verify=False               # ç¦ç”¨SSLéªŒè¯é¿å…è¯ä¹¦é—®é¢˜
            # æ³¨æ„: transportså‚æ•°åœ¨è¾ƒæ—§ç‰ˆæœ¬ä¸­ä¸æ”¯æŒï¼Œå·²ç§»é™¤
        )
        
        self.camera = None
        self.is_running = False
        self.is_connected = False
        
        # ğŸ”„ æ–­ç½‘é‡è¿ç›¸å…³
        self.reconnect_enabled = True
        self.reconnect_thread = None
        self.reconnect_interval = 5  # é‡è¿é—´éš”ï¼ˆç§’ï¼‰
        self.max_reconnect_interval = 60  # æœ€å¤§é‡è¿é—´éš”
        self.reconnect_attempts = 0
        self.last_disconnect_time = 0
        self.connection_stable_time = 10  # è¿æ¥ç¨³å®šæ—¶é—´ï¼ˆç§’ï¼‰
        
        # æ˜¾ç¤ºç›¸å…³
        self.display_frame = None
        self.frame_lock = threading.Lock()
        
        # ğŸ†• ç‰¹æ®Šæ˜¾ç¤ºæ¨¡å¼
        self.special_display_mode = False
        self.special_display_image = None
        self.special_display_end_time = 0
        
        # ğŸ†• éŸ³ç”»åŒæ­¥ç›¸å…³
        self.audio_display_sync_ready = False
        self.pending_composed_image = None
        self.pending_display_duration = 0
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'frames_sent': 0,
            'frames_received': 0,
            'last_send_time': 0,
            'last_receive_time': 0,
            'avg_latency': 0,
            'connection_time': 0
        }
        
        # è°ƒè¯•æ§åˆ¶
        self.debug_mode = False
        self.debug_frame_count = 0
        
        # ğŸ†• åˆå§‹åŒ–éŸ³é¢‘ç³»ç»Ÿ
        self._init_audio()
        
        # è®¾ç½®WebSocketäº‹ä»¶å¤„ç†
        self._setup_socket_events()
        
        print("ğŸ–¥ï¸ å®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")
    
    def _init_audio(self):
        """åˆå§‹åŒ–éŸ³é¢‘ç³»ç»Ÿ"""
        try:
            pygame.mixer.init()
            
            # ğŸ†• åŠ è½½æ‹ç…§éŸ³æ•ˆ
            audio_path = os.path.join("sources", "voice", "camera.mp3")
            if os.path.exists(audio_path):
                self.camera_sound = pygame.mixer.Sound(audio_path)
                print(f"âœ… æ‹ç…§éŸ³æ•ˆåŠ è½½æˆåŠŸ: {audio_path}")
            else:
                print(f"âš ï¸ æ‹ç…§éŸ³æ•ˆæ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
                self.camera_sound = None
        except Exception as e:
            print(f"âŒ éŸ³é¢‘ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
            self.camera_sound = None
    
    def play_camera_sound(self):
        """æ’­æ”¾æ‹ç…§éŸ³æ•ˆ"""
        try:
            if self.camera_sound:
                self.camera_sound.play()
                print("ğŸ”Š æ’­æ”¾æ‹ç…§éŸ³æ•ˆ")
        except Exception as e:
            print(f"âŒ æ’­æ”¾éŸ³æ•ˆå¤±è´¥: {e}")
    
    def _setup_socket_events(self):
        """è®¾ç½®WebSocketäº‹ä»¶å¤„ç†"""
        
        @self.sio.event
        def connect():
            print("ğŸ”— å·²è¿æ¥åˆ°æœåŠ¡å™¨")
            self.is_connected = True
            self.stats['connection_time'] = time.time()
            # ğŸ”„ è¿æ¥æˆåŠŸåé‡ç½®é‡è¿çŠ¶æ€
            self.reconnect_attempts = 0
            self.reconnect_interval = 5
        
        @self.sio.event
        def disconnect():
            print("âŒ ä¸æœåŠ¡å™¨æ–­å¼€è¿æ¥")
            self.is_connected = False
            self.last_disconnect_time = time.time()
            if self.is_running:
                print("ğŸ”„ æ£€æµ‹åˆ°æ–­çº¿ï¼Œå°†å¯åŠ¨é‡è¿æœºåˆ¶...")
                # ğŸ”„ ä½¿ç”¨æ–°çš„é‡è¿ç³»ç»Ÿ
                self.start_reconnect_thread()
        
        @self.sio.event
        def connect_error(data):
            print(f"âŒ è¿æ¥é”™è¯¯: {data}")
        
        @self.sio.event
        def connection_response(data):
            print(f"âœ… æœåŠ¡å™¨å“åº”: {data}")
        
        @self.sio.event
        def processed_frame(data):
            """æ¥æ”¶å¤„ç†åçš„å¸§"""
            try:
                if data.get('success'):
                    # å¤§å¹…å‡å°‘è°ƒè¯•è¾“å‡ºé¢‘ç‡
                    self.debug_frame_count += 1
                    should_debug = self.debug_mode and (self.debug_frame_count % 60 == 0)
                    
                    if should_debug:
                        print(f"ğŸ”§ DEBUG: å¤„ç†ç¬¬{self.debug_frame_count}å¸§")
                    
                    # è§£ç å¤„ç†åçš„å›¾åƒ
                    processed_image_b64 = data.get('processed_image')
                    if not processed_image_b64:
                        if should_debug:
                            print("âŒ DEBUG: æ²¡æœ‰processed_imageå­—æ®µ")
                        return
                    
                    try:
                        image_bytes = base64.b64decode(processed_image_b64)
                        nparr = np.frombuffer(image_bytes, np.uint8)
                        processed_frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
                        
                        if should_debug:
                            print(f"ğŸ”§ DEBUG: è§£ç å›¾åƒå°ºå¯¸: {processed_frame.shape if processed_frame is not None else 'None'}")
                        
                    except Exception as decode_error:
                        print(f"âŒ å›¾åƒè§£ç å¤±è´¥: {decode_error}")
                        return
                    
                    if processed_frame is not None:
                        # ğŸ”§ å¿«é€Ÿæ›´æ–°æ˜¾ç¤ºå¸§ï¼Œé¿å…é”ç«äº‰
                        with self.frame_lock:
                            # ğŸ†• æ£€æŸ¥æ˜¯å¦åœ¨ç‰¹æ®Šæ˜¾ç¤ºæ¨¡å¼
                            if not self.special_display_mode:
                                self.display_frame = processed_frame
                        
                        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                        self.stats['frames_received'] += 1
                        self.stats['last_receive_time'] = time.time()
                        
                        # è®¡ç®—å»¶è¿Ÿ
                        if 'timestamp' in data:
                            latency = time.time() - data['timestamp']
                            self._update_latency(latency)
                        
                        # å‡å°‘æ‰“å°é¢‘ç‡
                        if self.stats['frames_received'] % 60 == 0:
                            faces_count = len(data.get('faces', []))
                            processing_time = data.get('processing_time', 0)
                            print(f"ğŸ“¸ æ¥æ”¶å¸§: {self.stats['frames_received']}, äººè„¸æ•°={faces_count}, å¤„ç†æ—¶é—´={processing_time:.3f}s")
                    
                else:
                    print(f"âŒ æœåŠ¡å™¨å¤„ç†é”™è¯¯: {data.get('error', 'æœªçŸ¥é”™è¯¯')}")
                    
            except Exception as e:
                print(f"âŒ å¤„ç†æœåŠ¡å™¨å“åº”æ—¶å‡ºé”™: {str(e)}")
        
        # ğŸ†• æ·»åŠ æ‹ç…§äº‹ä»¶å¤„ç†
        @self.sio.event
        def photo_taken(data):
            """å¤„ç†æ‹ç…§äº‹ä»¶"""
            print("ğŸ“¸ æœåŠ¡å™¨é€šçŸ¥ï¼šç…§ç‰‡æ‹æ‘„å®Œæˆï¼")
            self.play_camera_sound()  # æ’­æ”¾æ‹ç…§éŸ³æ•ˆ
        
        # ğŸ†• æ·»åŠ éŸ³ç”»åŒæ­¥äº‹ä»¶å¤„ç†å™¨
        @self.sio.event
        def audio_and_display_sync(data):
            """å¤„ç†éŸ³é¢‘å’Œå›¾ç‰‡å±•ç¤ºåŒæ­¥äº‹ä»¶"""
            try:
                comment = data.get('comment', '')
                audio_filename = data.get('audio_filename', '')
                audio_data = data.get('audio_data', '')  # base64ç¼–ç çš„éŸ³é¢‘æ•°æ®
                photo_path = data.get('photo_path', '')
                emotion_type = data.get('emotion_type', '')
                start_display = data.get('start_display', False)
                
                print(f"ğŸµ æ”¶åˆ°éŸ³ç”»åŒæ­¥ä¿¡å·: {comment}")
                print(f"ğŸ”Š éŸ³é¢‘æ–‡ä»¶: {audio_filename}")
                
                if audio_data and start_display:
                    # è§£ç å¹¶ä¿å­˜éŸ³é¢‘æ–‡ä»¶
                    try:
                        import base64
                        import os
                        
                        # åˆ›å»ºæœ¬åœ°éŸ³é¢‘ç›®å½•
                        local_audio_dir = 'received_audio'
                        if not os.path.exists(local_audio_dir):
                            os.makedirs(local_audio_dir)
                        
                        # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
                        local_audio_path = os.path.join(local_audio_dir, audio_filename)
                        audio_bytes = base64.b64decode(audio_data)
                        with open(local_audio_path, 'wb') as f:
                            f.write(audio_bytes)
                        
                        print(f"ğŸ’¾ éŸ³é¢‘æ–‡ä»¶å·²ä¿å­˜: {local_audio_path}")
                        
                        # ç«‹å³æ’­æ”¾éŸ³é¢‘
                        self.play_generated_audio(local_audio_path)
                        
                        # è®¾ç½®éŸ³é¢‘åŒæ­¥æ ‡å¿—
                        self.audio_display_sync_ready = True
                        
                        # ğŸ†• æ£€æŸ¥æ˜¯å¦æœ‰ç­‰å¾…ä¸­çš„åˆæˆå›¾ç‰‡ï¼Œå¦‚æœæœ‰åˆ™ç«‹å³å±•ç¤º
                        if self.pending_composed_image is not None:
                            print(f"ğŸ¬ éŸ³é¢‘å¼€å§‹æ’­æ”¾ï¼ŒåŒæ­¥å±•ç¤ºç­‰å¾…ä¸­çš„åˆæˆå›¾ç‰‡")
                            self._start_display_composed_image(self.pending_composed_image, self.pending_display_duration)
                        else:
                            print(f"âœ… éŸ³ç”»åŒæ­¥å°±ç»ªï¼Œç­‰å¾…åˆæˆå›¾ç‰‡...")
                        
                    except Exception as audio_error:
                        print(f"âŒ éŸ³é¢‘å¤„ç†å¤±è´¥: {str(audio_error)}")
                        # å³ä½¿éŸ³é¢‘å¤„ç†å¤±è´¥ï¼Œä¹Ÿè¦å…è®¸å›¾ç‰‡å±•ç¤º
                        self.audio_display_sync_ready = True
                
            except Exception as e:
                print(f"âŒ å¤„ç†éŸ³ç”»åŒæ­¥äº‹ä»¶æ—¶å‡ºé”™: {str(e)}")
        
        # ğŸ†• æ·»åŠ åˆæˆå®Œæˆäº‹ä»¶å¤„ç†ï¼ˆéŸ³ç”»åŒæ­¥ç‰ˆæœ¬ï¼‰
        @self.sio.event
        def photo_composed(data):
            """å¤„ç†ç…§ç‰‡åˆæˆå®Œæˆäº‹ä»¶ï¼ˆç­‰å¾…éŸ³é¢‘åŒæ­¥ï¼‰"""
            try:
                print("ğŸ¨ æœåŠ¡å™¨é€šçŸ¥ï¼šç…§ç‰‡åˆæˆå®Œæˆï¼")
                
                composed_image_b64 = data.get('composed_image')
                display_duration = data.get('display_duration', 5)
                
                if composed_image_b64:
                    # è§£ç åˆæˆåçš„å›¾åƒ
                    image_bytes = base64.b64decode(composed_image_b64)
                    nparr = np.frombuffer(image_bytes, np.uint8)
                    composed_frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
                    
                    if composed_frame is not None:
                        # ğŸ†• æ£€æŸ¥æ˜¯å¦å·²æ”¶åˆ°éŸ³é¢‘åŒæ­¥ä¿¡å·
                        if self.audio_display_sync_ready:
                            # éŸ³é¢‘å·²å°±ç»ªï¼Œç«‹å³å±•ç¤ºå›¾ç‰‡
                            print(f"âœ… éŸ³ç”»åŒæ­¥å°±ç»ªï¼Œç«‹å³å±•ç¤ºåˆæˆå›¾ç‰‡ {display_duration} ç§’")
                            self._start_display_composed_image(composed_frame, display_duration)
                        else:
                            # éŸ³é¢‘è¿˜æœªå°±ç»ªï¼Œæš‚å­˜å›¾ç‰‡ç­‰å¾…åŒæ­¥
                            print(f"ğŸ•°ï¸ ç­‰å¾…éŸ³é¢‘åŒæ­¥ä¿¡å·ï¼Œæš‚å­˜åˆæˆå›¾ç‰‡...")
                            self.pending_composed_image = composed_frame
                            self.pending_display_duration = display_duration
                            
                            # è®¾ç½®è¶…æ—¶æœºåˆ¶ï¼Œå¦‚æœ10ç§’å†…æ²¡æœ‰æ”¶åˆ°éŸ³é¢‘åŒæ­¥ï¼Œå°±ç›´æ¥å±•ç¤º
                            def timeout_display():
                                time.sleep(10)
                                if self.pending_composed_image is not None and not self.audio_display_sync_ready:
                                    print(f"âš ï¸ éŸ³é¢‘åŒæ­¥è¶…æ—¶ï¼Œç›´æ¥å±•ç¤ºåˆæˆå›¾ç‰‡")
                                    self._start_display_composed_image(self.pending_composed_image, self.pending_display_duration)
                                    self.pending_composed_image = None
                                    self.pending_display_duration = 0
                            
                            timeout_thread = threading.Thread(target=timeout_display)
                            timeout_thread.daemon = True
                            timeout_thread.start()
                    
            except Exception as e:
                print(f"âŒ å¤„ç†åˆæˆå›¾ç‰‡æ—¶å‡ºé”™: {str(e)}")
        
        @self.sio.event
        def error(data):
            print(f"âš ï¸ æœåŠ¡å™¨é”™è¯¯: {data}")
        
        @self.sio.event
        def pong(data):
            """å¤„ç†pongå“åº”"""
            server_time = data.get('server_timestamp', 0)
            client_time = data.get('client_timestamp', 0)
            current_time = time.time()
            
            if client_time > 0:
                round_trip_time = current_time - client_time
                print(f"ğŸ“ Pingå»¶è¿Ÿ: {round_trip_time*1000:.1f}ms")
        
        @self.sio.event
        def stats_response(data):
            """å¤„ç†ç»Ÿè®¡ä¿¡æ¯å“åº”"""
            print("ğŸ“Š æœåŠ¡å™¨ç»Ÿè®¡ä¿¡æ¯:")
            print(f"   è¿æ¥å®¢æˆ·ç«¯: {data.get('connected_clients', 0)}")
            print(f"   å¤„ç†ç»Ÿè®¡: {data.get('processing_stats', {})}")
    
    def play_camera_sound(self):
        """æ’­æ”¾æ‹ç…§éŸ³æ•ˆ"""
        try:
            # åˆå§‹åŒ–pygame mixerï¼ˆå¦‚æœè¿˜æ²¡æœ‰åˆå§‹åŒ–ï¼‰
            if not pygame.mixer.get_init():
                pygame.mixer.init()
            
            # æŸ¥æ‰¾æ‹ç…§éŸ³æ•ˆæ–‡ä»¶
            camera_sound_path = os.path.join('sources', 'voice', 'camera.mp3')
            
            if os.path.exists(camera_sound_path):
                print(f"ğŸ”Š æ’­æ”¾æ‹ç…§éŸ³æ•ˆ: {camera_sound_path}")
                
                # ä½¿ç”¨pygameæ’­æ”¾éŸ³æ•ˆï¼ˆéé˜»å¡ï¼‰
                pygame.mixer.music.load(camera_sound_path)
                pygame.mixer.music.play()
                
                # ç­‰å¾…ä¸€å°æ®µæ—¶é—´ç¡®ä¿æ’­æ”¾å¼€å§‹ï¼Œä½†ä¸é˜»å¡
                time.sleep(0.1)
                
            else:
                print(f"âš ï¸ æ‹ç…§éŸ³æ•ˆæ–‡ä»¶ä¸å­˜åœ¨: {camera_sound_path}")
                print("ğŸ”Š æ’­æ”¾é»˜è®¤æ‹ç…§éŸ³æ•ˆ")
            
        except Exception as e:
            print(f"âŒ æ’­æ”¾æ‹ç…§éŸ³æ•ˆå¤±è´¥: {str(e)}")
    
    def play_generated_audio(self, audio_path):
        """æ’­æ”¾ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶ï¼ˆä½¿ç”¨Soundå¯¹è±¡é¿å…ä¸æ‹ç…§éŸ³æ•ˆå†²çªï¼‰"""
        try:
            # åˆå§‹åŒ–pygame mixerï¼ˆå¦‚æœè¿˜æ²¡æœ‰åˆå§‹åŒ–ï¼‰
            if not pygame.mixer.get_init():
                pygame.mixer.init()
            
            if os.path.exists(audio_path):
                print(f"ğŸµ å¼€å§‹æ’­æ”¾è¯„ä»·éŸ³é¢‘: {audio_path}")
                
                # ä½¿ç”¨Soundå¯¹è±¡æ’­æ”¾ï¼Œé¿å…ä¸musicé€šé“å†²çª
                sound = pygame.mixer.Sound(audio_path)
                sound_channel = sound.play()
                
                # ç­‰å¾…æ’­æ”¾å®Œæˆï¼ˆéé˜»å¡ï¼‰
                def wait_for_audio():
                    while sound_channel and sound_channel.get_busy():
                        time.sleep(0.1)
                    print(f"âœ… è¯„ä»·éŸ³é¢‘æ’­æ”¾å®Œæˆ: {audio_path}")
                
                # åœ¨æ–°çº¿ç¨‹ä¸­ç­‰å¾…æ’­æ”¾å®Œæˆ
                audio_thread = threading.Thread(target=wait_for_audio)
                audio_thread.daemon = True
                audio_thread.start()
                
            else:
                print(f"âš ï¸ è¯„ä»·éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
                
        except Exception as e:
            print(f"âŒ æ’­æ”¾è¯„ä»·éŸ³é¢‘å¤±è´¥: {str(e)}")
    
    def _start_display_composed_image(self, composed_frame, display_duration):
        """å¼€å§‹å±•ç¤ºåˆæˆå›¾ç‰‡"""
        try:
            print(f"ğŸ–¼ï¸ å¼€å§‹å±•ç¤ºåˆæˆå›¾ç‰‡ {display_duration} ç§’")
            
            with self.frame_lock:
                self.special_display_mode = True
                self.special_display_image = composed_frame
                self.special_display_end_time = time.time() + display_duration
                # æ¸…ç†æš‚å­˜çš„å›¾ç‰‡
                self.pending_composed_image = None
                self.pending_display_duration = 0
            
            # è®¾ç½®å®šæ—¶å™¨è‡ªåŠ¨é€€å‡ºç‰¹æ®Šæ˜¾ç¤ºæ¨¡å¼
            threading.Timer(display_duration, self._exit_special_display).start()
            
        except Exception as e:
            print(f"âŒ å±•ç¤ºåˆæˆå›¾ç‰‡å¤±è´¥: {str(e)}")
    
    def _exit_special_display(self):
        """é€€å‡ºç‰¹æ®Šæ˜¾ç¤ºæ¨¡å¼"""
        with self.frame_lock:
            self.special_display_mode = False
            self.special_display_image = None
            # é‡ç½®éŸ³ç”»åŒæ­¥æ ‡å¿—
            self.audio_display_sync_ready = False
            self.pending_composed_image = None
            self.pending_display_duration = 0
        print("ğŸ”„ è¿”å›å®æ—¶è¯†åˆ«ç•Œé¢")
    

    
    def _update_latency(self, latency):
        """æ›´æ–°å»¶è¿Ÿç»Ÿè®¡"""
        alpha = 0.1
        if self.stats['avg_latency'] == 0:
            self.stats['avg_latency'] = latency
        else:
            self.stats['avg_latency'] = (
                alpha * latency + (1 - alpha) * self.stats['avg_latency']
            )
    
    def connect_to_server(self):
        """è¿æ¥åˆ°æœåŠ¡å™¨"""
        try:
            print(f"ğŸ”„ æ­£åœ¨è¿æ¥åˆ°æœåŠ¡å™¨: {self.server_url}")
            
            # ğŸ§ Ubuntuå…¼å®¹æ€§: ä½¿ç”¨æ›´å®½æ¾çš„è¿æ¥å‚æ•°
            connect_params = {
                'wait_timeout': 15,  # å¢åŠ è¶…æ—¶æ—¶é—´
                'transports': ['websocket', 'polling']
            }
            
            # åœ¨Ubuntuä¸Šå¯èƒ½éœ€è¦ç¦ç”¨æŸäº›ä¼ è¾“æ–¹å¼
            import platform
            if platform.system() == 'Linux':
                print("ğŸ§ æ£€æµ‹åˆ°Linuxç³»ç»Ÿï¼Œä½¿ç”¨Ubuntuä¼˜åŒ–é…ç½®")
                connect_params['transports'] = ['polling', 'websocket']  # ä¼˜å…ˆä½¿ç”¨polling
            
            self.sio.connect(self.server_url, **connect_params)
            
            time.sleep(2)  # ç¨å¾®å¢åŠ ç­‰å¾…æ—¶é—´
            
            if self.sio.connected:
                self.is_connected = True
                self.reconnect_attempts = 0  # é‡ç½®é‡è¿è®¡æ•°
                self.reconnect_interval = 5  # é‡ç½®é‡è¿é—´éš”
                print("âœ… è¿æ¥æˆåŠŸ")
                return True
            else:
                self.is_connected = False
                print("âŒ è¿æ¥å¤±è´¥")
                return False
                
        except Exception as e:
            self.is_connected = False
            print(f"âŒ è¿æ¥æœåŠ¡å™¨å¤±è´¥: {str(e)}")
            # ğŸ§ Ubuntuç‰¹å®šé”™è¯¯å¤„ç†
            if 'timeout' in str(e).lower() or 'connection' in str(e).lower():
                print("ğŸ§ æ£€æµ‹åˆ°è¿æ¥è¶…æ—¶ï¼Œå¯èƒ½æ˜¯Ubuntuç½‘ç»œé…ç½®é—®é¢˜")
            return False
    
    def disconnect_from_server(self):
        """æ–­å¼€æœåŠ¡å™¨è¿æ¥"""
        try:
            self.is_connected = False
            self.last_disconnect_time = time.time()
            if self.sio.connected:
                self.sio.disconnect()
                print("âœ… å·²æ–­å¼€æœåŠ¡å™¨è¿æ¥")
        except Exception as e:
            print(f"âš ï¸ æ–­å¼€è¿æ¥æ—¶å‡ºé”™: {str(e)}")
    
    def start_reconnect_thread(self):
        """å¯åŠ¨é‡è¿çº¿ç¨‹"""
        if self.reconnect_thread is None or not self.reconnect_thread.is_alive():
            self.reconnect_thread = threading.Thread(target=self._reconnect_loop, daemon=True)
            self.reconnect_thread.start()
            print("ğŸ”„ é‡è¿çº¿ç¨‹å·²å¯åŠ¨")
    
    def stop_reconnect_thread(self):
        """åœæ­¢é‡è¿çº¿ç¨‹"""
        self.reconnect_enabled = False
        if self.reconnect_thread and self.reconnect_thread.is_alive():
            print("ğŸš« åœæ­¢é‡è¿çº¿ç¨‹")
    
    def _reconnect_loop(self):
        """é‡è¿å¾ªç¯"""
        while self.reconnect_enabled and self.is_running:
            try:
                # æ£€æŸ¥è¿æ¥çŠ¶æ€
                if not self.is_connected and not self.sio.connected:
                    self.reconnect_attempts += 1
                    
                    print(f"ğŸ”„ å°è¯•é‡è¿ ({self.reconnect_attempts}) - é—´éš”: {self.reconnect_interval}ç§’")
                    
                    # å°è¯•é‡è¿
                    if self.connect_to_server():
                        print("âœ… é‡è¿æˆåŠŸï¼")
                        # é‡è¿æˆåŠŸåç¨ç­‰ä¸€ä¸‹ï¼Œç¡®ä¿è¿æ¥ç¨³å®š
                        time.sleep(self.connection_stable_time)
                        continue
                    else:
                        print(f"âŒ é‡è¿å¤±è´¥ ({self.reconnect_attempts})")
                        
                        # é€æ¸å¢åŠ é‡è¿é—´éš”ï¼ˆæŒ‡æ•°é€€é¿ï¼‰
                        self.reconnect_interval = min(
                            self.reconnect_interval * 1.5, 
                            self.max_reconnect_interval
                        )
                
                # ç­‰å¾…ä¸‹æ¬¡æ£€æŸ¥
                time.sleep(self.reconnect_interval)
                
            except Exception as e:
                print(f"âŒ é‡è¿å¾ªç¯å‡ºé”™: {e}")
                time.sleep(self.reconnect_interval)
    
    def check_connection_health(self):
        """æ£€æŸ¥è¿æ¥å¥åº·çŠ¶æ€"""
        try:
            if self.sio.connected != self.is_connected:
                # è¿æ¥çŠ¶æ€ä¸ä¸€è‡´ï¼Œæ›´æ–°çŠ¶æ€
                self.is_connected = self.sio.connected
                
                if not self.is_connected:
                    print("âš ï¸ æ£€æµ‹åˆ°è¿æ¥æ–­å¼€ï¼Œå°†å¼€å§‹é‡è¿...")
                    self.last_disconnect_time = time.time()
                    # å¯åŠ¨é‡è¿çº¿ç¨‹ï¼ˆå¦‚æœå°šæœªå¯åŠ¨ï¼‰
                    self.start_reconnect_thread()
                    
        except Exception as e:
            print(f"âš ï¸ æ£€æŸ¥è¿æ¥å¥åº·çŠ¶æ€æ—¶å‡ºé”™: {e}")
    
    def init_camera(self, camera_id=0):
        """åˆå§‹åŒ–æ‘„åƒå¤´"""
        try:
            self.camera = cv2.VideoCapture(camera_id)
            
            if not self.camera.isOpened():
                print(f"âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´ {camera_id}")
                return False
            
            # è®¾ç½®æ‘„åƒå¤´å‚æ•°
            self.camera.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            self.camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            self.camera.set(cv2.CAP_PROP_FPS, 30)
            
            print(f"âœ… æ‘„åƒå¤´åˆå§‹åŒ–æˆåŠŸ: {camera_id}")
            return True
            
        except Exception as e:
            print(f"âŒ åˆå§‹åŒ–æ‘„åƒå¤´å¤±è´¥: {str(e)}")
            return False
    
    def capture_and_send_frames(self):
        """æ•è·å¹¶å‘é€è§†é¢‘å¸§"""
        frame_id = 0
        last_send_time = time.time()
        last_health_check = time.time()
        send_interval = 1.0 / 15  # 15fps
        health_check_interval = 5  # æ¯5ç§’æ£€æŸ¥ä¸€æ¬¡è¿æ¥å¥åº·
        
        while self.is_running:
            try:
                current_time = time.time()
                
                # ğŸ’š å®šæœŸæ£€æŸ¥è¿æ¥å¥åº·çŠ¶æ€
                if current_time - last_health_check > health_check_interval:
                    self.check_connection_health()
                    last_health_check = current_time
                
                if self.camera is None:
                    time.sleep(0.1)
                    continue
                
                ret, frame = self.camera.read()
                if not ret:
                    print("âš ï¸ æ— æ³•è¯»å–æ‘„åƒå¤´æ•°æ®")
                    time.sleep(0.1)
                    continue
                
                # æ§åˆ¶å‘é€é¢‘ç‡
                if current_time - last_send_time < send_interval:
                    time.sleep(0.01)
                    continue
                
                # åªåœ¨è¿æ¥æˆåŠŸæ—¶å‘é€æ•°æ®
                if self.is_connected and self.sio.connected:
                    try:
                        # ç¼–ç å›¾åƒ
                        _, buffer = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 70])
                        frame_data = base64.b64encode(buffer).decode('utf-8')
                        
                        # å‘é€æ•°æ®
                        self.sio.emit('video_frame', {
                            'frame_id': frame_id,
                            'image': frame_data,
                            'timestamp': current_time
                        })
                        
                        self.stats['frames_sent'] += 1
                        last_send_time = current_time
                        frame_id += 1
                        
                    except Exception as send_error:
                        print(f"âŒ å‘é€æ•°æ®å¤±è´¥: {str(send_error)}")
                        # å‘é€å¤±è´¥å¯èƒ½æ˜¯è¿æ¥é—®é¢˜ï¼Œæ›´æ–°çŠ¶æ€
                        self.is_connected = False
                        self.start_reconnect_thread()  # ğŸ”„ å¯åŠ¨é‡è¿
                
                # æ§åˆ¶å¾ªç¯é¢‘ç‡
                time.sleep(0.01)
                
            except Exception as e:
                print(f"âŒ æ•è·è§†é¢‘å¸§æ—¶å‡ºé”™: {str(e)}")
                time.sleep(0.1)
        
        print("ğŸ”„ æ•è·çº¿ç¨‹ç»“æŸ")
    
    def display_frames(self):
        """æ˜¾ç¤ºè§†é¢‘å¸§"""
        print("ğŸ–¥ï¸ å¼€å§‹æ˜¾ç¤ºçº¿ç¨‹")
        
        # åœ¨æ˜¾ç¤ºçº¿ç¨‹ä¸­åˆ›å»ºçª—å£
        try:
            cv2.namedWindow("Face Emotion Recognition Client", cv2.WINDOW_NORMAL)
            cv2.resizeWindow("Face Emotion Recognition Client", 800, 600)
            print("âœ… æ˜¾ç¤ºçª—å£åˆ›å»ºæˆåŠŸ")
        except Exception as window_error:
            print(f"âŒ åˆ›å»ºæ˜¾ç¤ºçª—å£å¤±è´¥: {window_error}")
            return
        
        display_count = 0
        last_status_print = 0
        
        while self.is_running:
            try:
                display_count += 1
                current_time = time.time()
                
                # ğŸ†• è·å–è¦æ˜¾ç¤ºçš„å¸§ï¼ˆæ”¯æŒç‰¹æ®Šæ˜¾ç¤ºæ¨¡å¼ï¼‰
                display_copy = None
                with self.frame_lock:
                    if self.special_display_mode and self.special_display_image is not None:
                        # ğŸŒŸ ç‰¹æ®Šæ˜¾ç¤ºæ¨¡å¼ï¼šæ˜¾ç¤ºåˆæˆå›¾ç‰‡ï¼ˆæ— å€’è®¡æ—¶ï¼‰
                        display_copy = self.special_display_image.copy()
                        
                    elif self.display_frame is not None:
                        # ğŸ”„ æ­£å¸¸æ¨¡å¼ï¼šæ˜¾ç¤ºå®æ—¶è¯†åˆ«ç”»é¢
                        display_copy = self.display_frame.copy()
                
                if display_copy is None:
                    # åˆ›å»ºç­‰å¾…ç”»é¢
                    display_copy = np.zeros((480, 640, 3), dtype=np.uint8)
                    cv2.putText(display_copy, "Waiting for server response...", 
                              (80, 240), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
                
                # ğŸ†• åªåœ¨æ­£å¸¸æ¨¡å¼ä¸‹æ·»åŠ çŠ¶æ€ä¿¡æ¯
                if not self.special_display_mode:
                    self._draw_status_info(display_copy)
                
                # æ˜¾ç¤ºå›¾åƒ
                cv2.imshow("Face Emotion Recognition Client", display_copy)
                
                # å¿…é¡»è°ƒç”¨waitKeyï¼Œå¦åˆ™çª—å£æ— æ³•å“åº”
                key = cv2.waitKey(1) & 0xFF
                
                # å¤„ç†æŒ‰é”®
                if key == 27 or key == ord('q'):  # ESCæˆ–Qé€€å‡º
                    print("ğŸ”„ ç”¨æˆ·è¯·æ±‚é€€å‡º")
                    self.stop()
                    break
                elif key == ord('p'):  # På‘é€ping
                    if self.is_connected:
                        self.sio.emit('ping', {'timestamp': time.time()})
                        print("ğŸ“ å‘é€Ping")
                elif key == ord('s'):  # Sè·å–ç»Ÿè®¡ä¿¡æ¯
                    if self.is_connected:
                        self.sio.emit('get_stats')
                        print("ğŸ“Š è·å–ç»Ÿè®¡ä¿¡æ¯")
                elif key == ord('d'):  # Dé”®åˆ‡æ¢è°ƒè¯•æ¨¡å¼
                    self.debug_mode = not self.debug_mode
                    print(f"ğŸ”§ è°ƒè¯•æ¨¡å¼: {'å¼€å¯' if self.debug_mode else 'å…³é—­'}")
                elif key == ord('t'):  # ğŸ†• Té”®æµ‹è¯•éŸ³æ•ˆ
                    self.play_camera_sound()
                    print("ğŸ”Š æµ‹è¯•éŸ³æ•ˆæ’­æ”¾")
                
                # å®šæœŸæ‰“å°çŠ¶æ€ï¼ˆä¸è¦å¤ªé¢‘ç¹ï¼‰
                if current_time - last_status_print > 5.0:  # æ¯5ç§’æ‰“å°ä¸€æ¬¡
                    mode_info = "ç‰¹æ®Šæ˜¾ç¤º" if self.special_display_mode else "å®æ—¶è¯†åˆ«"
                    print(f"ğŸ“º æ˜¾ç¤ºçŠ¶æ€: å¸§{display_count}, æ¨¡å¼={mode_info}, è¿æ¥={self.is_connected}, å‘é€={self.stats['frames_sent']}, æ¥æ”¶={self.stats['frames_received']}")
                    last_status_print = current_time
                
                # æ§åˆ¶æ˜¾ç¤ºé¢‘ç‡ï¼Œé¿å…CPUå ç”¨è¿‡é«˜
                time.sleep(0.030)  # çº¦33fpsæ˜¾ç¤ºé¢‘ç‡
                
            except Exception as e:
                print(f"âŒ æ˜¾ç¤ºè§†é¢‘å¸§æ—¶å‡ºé”™: {str(e)}")
                time.sleep(0.1)
        
        print("ğŸ”„ æ˜¾ç¤ºçº¿ç¨‹ç»“æŸ")
    
    def _draw_status_info(self, image):
        """åœ¨å›¾åƒä¸Šç»˜åˆ¶çŠ¶æ€ä¿¡æ¯"""
        height, width = image.shape[:2]
        
        # è¿æ¥çŠ¶æ€
        if self.is_connected:
            status_text = "Connected"
            status_color = (0, 255, 0)
        else:
            # ğŸ”„ æ˜¾ç¤ºé‡è¿çŠ¶æ€
            if self.reconnect_thread and self.reconnect_thread.is_alive():
                status_text = f"Reconnecting... ({self.reconnect_attempts})"
                status_color = (0, 165, 255)  # æ©™è‰²
            else:
                status_text = "Disconnected"
                status_color = (0, 0, 255)
        
        cv2.putText(image, status_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, status_color, 2)
        
        # ç»Ÿè®¡ä¿¡æ¯
        if self.is_connected:
            stats_text = f"Sent: {self.stats['frames_sent']} | Received: {self.stats['frames_received']}"
            cv2.putText(image, stats_text, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
            
            latency_text = f"Latency: {self.stats['avg_latency']*1000:.1f}ms"
            cv2.putText(image, latency_text, (10, 85), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        else:
            # ğŸ”„ æ˜¾ç¤ºé‡è¿ä¿¡æ¯
            if self.reconnect_attempts > 0:
                reconnect_text = f"Reconnect attempts: {self.reconnect_attempts}"
                cv2.putText(image, reconnect_text, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)
                
                interval_text = f"Next attempt in: {int(self.reconnect_interval)}s"
                cv2.putText(image, interval_text, (10, 85), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)
        
        # ğŸ†• ç®€åŒ–æ§åˆ¶æç¤ºï¼ˆä»…ä¿ç•™é€€å‡ºï¼‰
        controls_text = "Press ESC or Q to Exit"
        cv2.putText(image, controls_text, (10, height-20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)
    
    def start(self):
        """å¯åŠ¨å®¢æˆ·ç«¯"""
        print("ğŸš€ å¯åŠ¨äººè„¸æƒ…æ„Ÿè¯†åˆ«å®¢æˆ·ç«¯...")
        
        # åˆå§‹åŒ–æ‘„åƒå¤´
        if not self.init_camera():
            print("âŒ æ— æ³•åˆå§‹åŒ–æ‘„åƒå¤´")
            return False
        
        # è¿æ¥æœåŠ¡å™¨
        if not self.connect_to_server():
            print("âŒ æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨ï¼Œå°†å¯åŠ¨é‡è¿æœºåˆ¶")
            # ğŸ”„ å¯åŠ¨é‡è¿çº¿ç¨‹
            self.start_reconnect_thread()
        
        self.is_running = True
        
        # å¯åŠ¨çº¿ç¨‹
        capture_thread = threading.Thread(target=self.capture_and_send_frames)
        display_thread = threading.Thread(target=self.display_frames)
        
        capture_thread.daemon = True
        display_thread.daemon = True
        
        capture_thread.start()
        display_thread.start()
        
        print("âœ… å®¢æˆ·ç«¯å¯åŠ¨å®Œæˆ")
        print("ğŸ“‹ æ§åˆ¶è¯´æ˜:")
        print("   ESCæˆ–Qé”®: é€€å‡ºç¨‹åº")
        print("   Pé”®: å‘é€Pingæµ‹è¯•å»¶è¿Ÿ")
        print("   Sé”®: è·å–æœåŠ¡å™¨ç»Ÿè®¡ä¿¡æ¯")
        print("   Dé”®: åˆ‡æ¢è°ƒè¯•æ¨¡å¼")
        
        try:
            display_thread.join()
        except KeyboardInterrupt:
            print("\nğŸ”„ æ¥æ”¶åˆ°ä¸­æ–­ä¿¡å·...")
        finally:
            self.stop()
        
        return True
    
    def stop(self):
        """åœæ­¢å®¢æˆ·ç«¯"""
        print("ğŸ”„ æ­£åœ¨åœæ­¢å®¢æˆ·ç«¯...")
        
        self.is_running = False
        
        # ğŸš« åœæ­¢é‡è¿çº¿ç¨‹
        self.stop_reconnect_thread()
        
        # æ–­å¼€æœåŠ¡å™¨è¿æ¥
        self.disconnect_from_server()
        
        # é‡Šæ”¾æ‘„åƒå¤´
        if self.camera is not None:
            self.camera.release()
            self.camera = None
        
        # å…³é—­æ˜¾ç¤ºçª—å£
        cv2.destroyAllWindows()
        
        print("âœ… å®¢æˆ·ç«¯å·²åœæ­¢")

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='äººè„¸æƒ…æ„Ÿè¯†åˆ«å®¢æˆ·ç«¯')
    parser.add_argument('--server', default='http://test2.heihet09.com', 
                       help='æœåŠ¡å™¨åœ°å€ (é»˜è®¤: http://test2.heihet09.com)')
    parser.add_argument('--camera', type=int, default=0, 
                       help='æ‘„åƒå¤´ID (é»˜è®¤: 0)')
    
    args = parser.parse_args()
    
    # åˆ›å»ºå¹¶å¯åŠ¨å®¢æˆ·ç«¯
    client = FaceEmotionClient(server_url=args.server)
    client.start()

if __name__ == '__main__':
    main()
